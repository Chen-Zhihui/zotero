HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION

HANDBOOK OF MATHEMATICAL MODELS
IN COMPUTER VISION
Edited by Nikos Paragios Ecole Nationale des Fonts et Chaussees Yunmei Chen University of Florida Olivier Faugeras INRIA
Springer

Library of Congress Cataloging-in-Publication Data
A CLP. Catalogue record for this book is available from the Library of Congress.
Handbook of Mathematical Models in Computer Vision, Edited by Nikos Paragios, Yunmei Chen and Olivier Faugeras
p.cm.
ISBN-10: (HB) 0-387-26371-3 ISBN-13: (HB) 978-0387-26371-7 ISBN-10: (eBook) 0-387-28831-7 ISBN-13: (eBook) 978-0387-28831-4 Printed on acid-free paper.

Copyright © 2006 by Springer Science+Business Media, Inc. All rights reserved. This work may not be translated or copied m whole or in part without the written permission of the publisher [Springer Science+Business Media, Inc., 233 Spring Street, New York, NY 10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in connection with any form of information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed is forbidden. The use in this publication of trade names, trademarks, service marks and similar terms, even if they are not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights.

Printed in the United States of America.

9 8765432 1 springeronline.com

SPIN 11055662 (HC) / 11552987 (eBook)

Contents

Preface

xix

List of Contributors

xxiii

I Image Reconstruction

1

1 Diffusion Filters and Wavelets: What Can They Learn from Each

Other?

3

J. Weickert, G. Steidl, P. Mrazek, M. Welk, and T. Brox

1.1 Introduction

3

1.2 Basic Methods

4

1.2.1 Wavelet Shrinkage

4

1.2.2 Nonlinear Diffusion Filtering

5

1.3 Relations for Space-Discrete Diffusion

6

1.3.1 Equivalence for Two-Pixel Signals

6

1.3.2 A Wavelet-Inspired Scheme for TV Diffusion of

Signals

7

1.3.3 Generalisations to Images

8

1.4 Relations for Fully Discrete Diffusion

9

1.4.1 Diffusion-Inspired Shrinkage Functions

9

1.4.2 Wavelet Shrinkage with Improved Rotation Invariance . 10

1.4.3 Diffusion-Inspired Wavelet Shrinkage of Colour

Images

13

1.5 Wavelets with Higher Vanishing Moments

13

1.6 Summary

16

2 Total Variation Image Restoration: Overview and Recent Develop-

ments

17

T. Chan, S. Esedoglu, F. Park and A. Yip

2.1 Introduction

17

2.2 Properties and Extensions

19

2.2.1 BV Space and Basic Properties

19

2.2.2 Multi-channel TV

20

vi

Contents

2.2.3 Scale

20

2.3 Caveats

21

2.4 Variants

22

2.4.1 Iterated Refinement

22

2.4.2 L^ Fitting

23

2.4.3 Anisotropic TV

24

2.4.4 //^'PRegularization and Inf Convolution

25

2.5 Further Applications to Image Reconstruction

26

2.5.1 Deconvolution

26

2.5.2 Inpainting

27

2.5.3 Texture and Multiscale Decompositions

28

2.6 Numerical Methods

29

2.6.1 Artificial Time Marching and Fixed Point Iteration . . 29

2.6.2 DuaHty-based Methods

30

3 PDE-Based Image and Surface Inpainting

33

M. Bertalmio, V. Caselles, G. Haro, and G. Sapiro

3.1 Introduction

33

3.2 Inpaintingby Propagation of Information

36

3.2.1 Image Inpainting

36

3.2.2 Navier-Stokes Inpainting

40

3.3 Variational Models for Filling-In

42

3.3.1 Elastica-based Reconstruction of Level Lines

43

3.3.2 Joint Interpolation of Vector Fields and Gray Levels . . 45

3.3.3 A Variant and Mathematical Results

48

3.3.4 Experimental Results

50

3.4 Surface Reconstruction: The Laplace and the Absolute

Minimizing Lipschitz Extension Interpolation

52

3.4.1 Experimental Results

54

3.5 Dealing with texture

55

3.5.1 Texture Synthesis by Non-Parametric Sampling . . . . 56

3.5.2 Inpainting with Image Decomposition

56

3.5.3 Exemplar-based Inpainting

58

3.6 Other Approaches

58

3.6.1 Other PDE-based Models

58

3.6.2 Miscellaneous

59

3.7 Concluding Remarks

60

3.8 Appendix

60

3.9 Acknowledgments

61

II Boundary Extraction,

Segmentation and Grouping

63

4 Levelings: Theory and Practice

65

Contents

vii

F. Meyer

4.1 Introduction

65

4.2 Binary connected operators

66

4.3 Flat grey-tone connected operators

67

4.3.1 Level by level construction

67

4.3.2 A morphological characterization

68

4.4 Extended connected operators

68

4.4.1 Construction of floodings, razings, flattenings and

levelings

70

4.4.1.1 Construction of floodings, razings,

flattenings and levelings

70

4.5 Levelings for image simplification

71

4.5.1 Varying (a,/?)

72

4.5.2 Varying the marker function h

73

4.5.3 Multiscale

filtering

74

4.5.3.1 Construction of a hierarchy based on

increasing

floodings

74

4.5.3.2 Construction of a hierarchy based on

quasi-flat zones

76

4.6 Conclusion

77

5 Graph Cuts in Vision and Graphics: Theories and Applications

79

Y. Boykov and O. Veksler

5.1 Introduction

79

5.2 Graph Cuts Basics

80

5.2.1 The Min-Cut and Max-Flow Problem

81

5.2.2 Algorithms for the Min-Cut and Max-Flow Problem . . 81

5.3 Graph Cuts for Binary Optimization

82

5.3.1 Example: Binary Image Restoration

82

5.3.2 General Case of Binary Energy Minimization

84

5.4 Graph Cuts as Hypersurfaces

84

5.4.1 Basic idea

85

5.4.2 Topological properties of graph cuts

86

5.4.3 Applications of graph cuts as hypersurfaces

87

5.4.4 Theories connecting graph-cuts and hypersurfaces in

R^

90

5.5 Generalizing Graph Cuts for Multi-Label Problems

92

5.5.1 Exact Multi-Label Optimization

92

5.5.2 Approximate Optimization

94

5.5.2.1 Local Minimum with Respect to Expansion

and Swap Moves

95

6 Minimal Paths and Fast Marching Methods for Image Analysis

97

L. Cohen

6.1 Introduction

97

viii

Contents

6.2 Minimal Paths

98

6.2.1 Geometrical optics

98

6.2.2 Global Minimum for active contours

99

6.2.3 Problem formulation

99

6.2.4 Fast Marching Resolution

100

6.2.5 2D Up-Wind Scheme

102

6.2.6 Minimal Paths in 3D

102

6.2.7 Simultaneous Front Propagation

103

6.2.8 Simultaneous estimate of the path length

104

6.3 Minimal paths from a set of endpointsp/c

105

6.4 Multiple minimal paths between regions/?it

107

6.5 Segmentation by Fast Marching

108

6.6 Centered Minimal Paths and virtual endoscopy

110

6.7 Conclusion

Ill

7 Integrating Shape and Texture in Deformable Models: from Hybrid

Methods to Metamorphs

113

D. Metaxas, X. Huang and T. Chen

7.1 Introduction

113

7.2 Hybrid Segmentation Method

116

7.2.1 Gibbs Models

116

7.2.2 Deformable models in the Hybrid Framework

118

7.2.3 Integration ofDeformable Models and Gibbs Models . 119

7.3 Metamorphs: Deformable Shape and Texture Models

120

7.3.1 The Metamorphs Model representations

120

7.3.1.1 The Model's Shape Representation

120

7.3.1.2 The Model's Deformations

121

7.3.1.3 The Model's Texture

122

7.3.2 The Metamorph Dynamics

123

7.3.2.1 The Shape Data Terms

123

7.3.2.2 The Intensity Data Terms

125

7.3.3 Model Evolution

126

7.3.4 The Model Fitting Algorithm and Experimental

Results

127

7.4 Conclusions

128

8 Variational Segmentation with Shape Priors

131

M. Bergtholdt, D. Cremers and C. Schnorr

8.1 Introduction

131

8.2 Shape Representation

133

8.2.1 Parametric Contour Representations, Geometric

Distances, and Invariance

133

8.2.2 Matching Functionals and Psychophysical Distance

Measures

134

8.3 Learning Shape Statistics

136

Contents

ix

8.3.1 Shape Distances in Kernel Feature Space

136

8.3.2 Structure-Preserving Embedding and Clustering . . . . 137

8.4 Variational Segmentation and Shape Priors

139

8.4.1 Variational Approach

139

8.4.2 Kernel-based Invariant Shape Priors

141

8.4.3 Shape Priors based on the Matching Distance

141

8.4.4 Experimental Results

142

8.5 Conclusion and Further Work

142

9 Curve Propagation, Level Set Methods and Grouping

145

N. Paragios

9.1 Introduction

145

9.2 On the Propagation of Curves

146

9.2.1 Level Set Method

147

9.2.2 Optimisation and Level Set Methods

149

9.3 Data-driven Segmentation

151

9.3.1 Boundary-based Segmentation

151

9.3.2 Region-based Segmentation

152

9.4 Prior Knowledge

154

9.4.1 Average Models

154

9.4.2 Prior Knowledge through Linear Shape Spaces . . . . 157

9.5 Discussion

159

10 On a Stochastic Model of Geometric Snalces

161

A. Yezzi, D. Nain, G. Unal, O. Zeitouni and A. Tannenbaum

10.1 Introduction

161

10.2 Overview of Geodesic Snake Models

163

10.3 Birth and Death Zero Range Particle Systems

163

10.4 Poisson System Simulation

164

10.5 Choosing a Random Event

166

10.5.1 Using a List of Event Tokens

166

10.5.2 Virtual Token List Method

167

10.6 Similarity Invariant Flows

168

10.6.1 Heat Equation and Similarity Flows

169

10.6.2 Gradient Flow

170

10.7 Stochastic Snakes

171

10.7.1 Polygon representation and construction

171

10.8 Experimental Results

173

10.9 Conclusions and Future Research

174

III Shape Modeling & Registration

175

11 Invariant Processing and Occlusion Resistant Recognition of Pla-

nar Shapes

177

X

Contents

A. Bruckstein

11.1 Introduction

177

11.2 Invariant Point Locations and Displacements

178

11.3 Invariant Boundary Signatures for Recognition under Partial

Occlusions

182

11.4 Invariant Processing of Planar Shapes

184

11.5 Concluding Remarks

188

12 Planar Shape Analysis and Its Applications in Image-Based Infer-

ences

189

A. Srivastava, S. Joshi, D. Kaziska and D. Wilson

12.1 Introduction

189

12.2 A Framework for Planar Shape Analysis

191

12.3 Clustering of Shapes

194

12.4 Interpolation of Shapes in Echocardiographic

Image-Sequences

196

12.5 Study of Human Silhouettes in Infrared Images

200

12.5.1 TPCA Shape Model

200

12.5.2 Bayesian Shape Estimation

202

12.6 Summary & Discussion

202

13 Diffeomorphic Point Matching

205

H. Guo, A. Rangarajan and S. Joshi

13.1 Introduction

205

13.2 Diffeomorphic Landmark Matching

206

13.3 Diffeomorphic Point Shape Matching

214

13.4 Discussion

219

14 Uncertainty-Driven, Point-Based Image Registration

221

C. Stewart

14.1 Introduction

221

14.2 Objective Function, ICP and Normal Distances

223

14.3 Parameter Estimates and Covariance Matrices

226

14.4 Stable Sampling of ICP Constraints

228

14.5 Dual-Bootstrap ICP

230

14.6 Discussion and Conclusion

234

IV Motion Analysis, Optical Flow & Tracking

237

15 Optical Flow Estimation

239

D. Fleet and Y. Weiss

15.1 Introduction

239

15.2 Basic Gradient-Based Estimation

240

15.3 Iterative Optical Flow Estimation

243

Contents

xi

15.4 Robust Motion Estimation

246

15.5 Motion Models

247

15.6 Global Smoothing

249

15.7 Conservation Assumptions

250

15.8 Probabilistic Formulations

252

15.9 Layered Motion

253

15.10 Conclusions

256

16 From Bayes to PDEs in Image Warping

259

M. Nielsen and B. Markussen

16.1 Motivation and problem statement

259

16.2 Admissible warps

260

16.3 Bayesian formulation of warp estimation

262

16.4 Likelihood: Matching criteria

264

16.5 Prior: Smoothness criteria

266

16.6 Warp time and computing time

269

16.7 From fluid registration to diffeomorphic minimizers

270

16.8 Discussion and open problems

271

17 Image Alignment and Stitching

273

R. Szeliski

17.1 Introduction

273

17.2 Motion models

274

17.3 Direct and feature-based alignment

277

17.3.1 Direct methods

277

17.3.2 Feature-based registration

279

17.3.3 Direct vs. feature-based

282

17.4 Global registration

283

17.4.1 Bundle adjustment

283

17.4.2 Parallax removal

285

17.4.3 Recognizing panoramas

285

17.5 Choosing a compositing surface

286

17.6 Seam selection and pixel blending

287

17.7 Extensions and open issues

291

18 Visual Tracking: A Short Research Roadmap

293

A. Blake

18.1 Introduction

293

18.2 Simple appearance models

294

18.2.1 Simple patches

294

18.2.2 Blobs

295

18.2.3 Background maintenance

295

18.3 Active contours

296

18.3.1 Snakes

296

18.3.2 Parametric structures

297

xii

Contents

18.3.3 Affine contours

298

18.3.4 Nonrigidity

300

18.3.5 Robust curve distances

300

18.4 Spatio-temporal filtering

301

18.4.1 Dynamical models

301

18.4.2 Kalman filter for point features

302

18.4.3 Kalman filter for contours

303

18.4.4 Particle filter

303

18.5 Further topics

306

19 Shape Gradient for Image and Video Segmentation

309

S. Jehan-Besson, A. Herbulot, M. Barlaud, G. Aubert

19.1 Introduction

309

19.2 Problem Statement

310

19.3 From shape derivation tools towards region-based active

contours models

312

19.3.1 Shape derivation tools

313

19.3.1.1 Introduction of transformations

313

19.3.1.2 Relations between the derivatives

313

19.3.2 Derivation of boundary-based terms

314

19.3.3 Derivation of region-based terms

315

19.3.3.1 Region-independent descriptors

315

19.3.3.2 Region-dependent descriptors

315

19.4 Segmentation using Statistical Region-dependent descriptors . 317

19.4.1 Examples of Descriptors based on parametric statistics . 319

19.4.1.1 Region-dependent descriptors using the

mean

319

19.4.1.2 Region-dependent descriptors based on the

variance

319

19.4.2 Descriptors based on non parametric statistics

320

19.4.2.1 Region-dependent descriptors based on non

parametric pdfs of image features

320

19.4.2.2 Minimization of the distance between pdfs

for tracking

321

19.5 Discussion

322

20 Model-Based Human Motion Capture

325

I. Kakadiaris and C. Barron

20.1 Introduction

325

20.2 Methods

327

20.2.1 Human body model acquisition

328

20.2.2 Model-based tracking

331

20.3 Results

334

20.4 Discussion

338

Contents

xiii

21 Modeling Dynamic Scenes: An Overview of Dynamic Textures

341

G. Doretto and S. Soatto

21.1 Introduction

341

21.1.1 Related work

343

21.2 Representation of dynamic textures

344

21.3 Learning dynamic textures

344

21.3.1 Closed-form solution

346

21.4 Model validation

347

21.5 Recognition

349

21.5.1 Distances between dynamic texture models

349

21.5.2 Performance of the nearest neighbor classifier

350

21.6 Segmentation

351

21.7 Discussion

355

V 3D from Images, Projective Geometry & Stereo Recon-

struction

357

22 Differential Geometry from the Frenet Point of View: Boundary

Detection, Stereo, Texture and Color

359

S. Zucker

22.1 Introduction

359

22.2 Introduction to Frenet-Serret

361

22.3 Co-Circularity in M^ x 5^

363

22.3.1 Multiple Orientations and Product Spaces

364

22.4 Stereo: Inferring Frenet 3-Frames from 2-Frames

365

22.5 Covariant Derivatives, Oriented Textures, and Color

367

22.5.1 Hue Flows

371

22.6 Discussion

372

23 Shape From Shading

375

E. Prados and O. Faugeras

23.1 Introduction

375

23.2 Mathematical formulation of the SFS problem

377

23.2.1 "Orthographic SFS" with a far light source

377

23.2.2 "Perspective SFS" with a far light source

378

23.2.3 "Perspective SFS" with a point light source at the

optical center

378

23.2.4 A generic Hamiltonian

379

23.3 Mathematical study ofthe SFS problem

379

23.3.1 Related work

379

23.3.2 Nonuniqueness and characterization of a solution . . . 380

23.4 Numerical solutions by "Propagation and PDEs methods" . . . 382

23.4.1 Related work

382

xiv

Contents

23.4.2 An example of provably convergent numerical

method: Prados and Faugeras' method

383

23.5 Examples of numerical results

385

23.5.1 Document restoration using SFS

385

23.5.2 Face reconstruction from SFS

387

23.5.3 Potential applications to medical images

387

23.6 Conclusion

388

24 3D from Image Sequences: Calibration, Motion and Shape Recov-

ery

389

M. Pollefeys

24.1 Introduction

389

24.1.1 Notations and background

390

24.2 Relating images

392

24.2.1 Epipolar geometry computation

392

24.3 Structure and motion recovery

393

24.3.1 Initial structure and motion

394

24.3.2 Updating the structure and motion

395

24.3.3 Refining structure and motion

396

24.3.4 Upgrading from projective to metric

396

24.4 Dense surface estimation

398

24.4.1 Rectification and stereo matching

398

24.4.2 Multi-view linking

399

24.5 3D surface reconstruction

400

24.6 Conclusion

402

25 Multi-view Reconstruction of Static and Dynamic Scenes

405

M. Agrawal, A. Mittal and L. Davis

25.1 Introduction

405

25.2 Reconstruction of Static Scenes

406

25.2.1 Visual Hull

407

25.2.2 Voxel Coloring

407

25.2.3 Space Carving

409

25.2.4 ProbabiHstic Approaches

411

25.2.5 ProbabiHstic Space Carving

411

25.2.6 Roxels: Responsibility Weighted Voxels

412

25.2.7 ProbabiHstic Surface Reconstruction

412

25.2.8 ProbabiHstic Image-Based Stereo

415

25.3 Reconstruction of Dynamic Scenes

416

25.3.1 Visual Hull Algorithms

416

25.3.2 Approximate 3D Localization of Targets for

Surveillance

416

25.4 Sensor Planning

419

25.5 Conclusion

421

Contents

xv

26 Graph Cut Algorithms for Binocular Stereo with Occlusions

423

V. Kolmogorov and R. Zabih

26.1 Traditional stereo methods

423

26.1.1 Energy minimization via graph cuts

425

26.2 Stereo with occlusions

426

26.2.1 Notation

428

26.3 Voxel labeling algorithm

429

26.4 Pixel labeling algorithm

430

26.5 Minimizing the energy

431

26.6 Experimental results

432

26.6.1 Implementational details

432

26.6.2 Algorithm performance

433

26.7 Conclusions

434

27 Modelling Non-Rigid Dynamic Scenes from Multi-View Image

Sequences

439

J.-P. Pons, R. Keriven and O. Faugeras

27.1 Introduction

439

27.2 Previous Work

440

27.2.1 Multi-view complete stereovision

440

27.2.2 Scene flow estimation

442

27.2.3 Shape-motion integration

443

27.3 The Prediction Error as a New Metric for Stereovision and

Scene Flow Estimation

443

27.3.1 Stereovision

445

27.3.2 Scene

flow

446

27.3.3 Some similarity measures

447

27.4 Experimental Results

448

27.4.1 Stereovision

449

27.4.2 Stereovision + scene

flow

450

27.5 Conclusion and Future Work

451

VI Applications: Medical Image Analysis

453

28 Interactive Graph-Based Segmentation Methods in Cardiovascular

Imaging

455

L. Grady, Y. Sun and J. Williams

28.1 Introduction

455

28.2 Characteristic Behaviors of the Algorithms

456

28.3 Applications on CT Cardiovascular data

459

28.3.1 Segmenting Individual Heart Chambers using Graph

Cuts

460

28.3.2 Multi-Resolution Banded Graph Cuts

460

28.3.3 Empirical Results

461

xvi

Contents

28.3.4 Random Walks for Simultaneous Chamber

Segmentation

462

28.3.5 The Random Walker Algorithm

463

28.3.6 Numerical solution

464

28.3.7 Empirical Results

465

28.3.8 Isoperimetric algorithm

466

28.3.9 Bone-Vessel Separation

467

28.4 Conclusions

469

29 3D Active Shape and Appearance Models in Cardiac Image

Analysis

471

B. Lelieveldt, A. Frangi, S. Mitchell, H. van Assen, S. Ordas, J. Reiber

and M. Sonka

29.1 Introduction

471

29.1.1 Background

472

29.1.2 Issues inherent to 3D extension

474

29.2 Methods

475

29.2.1 3D Point Distribution Models

475

29.2.2 3D Active Shape Models

476

29.2.3 3D and 4D Active Appearance Models

479

29.2.3.1 2D + time Active Appearance Models . . . . 479

29.2.3.2 3D Active Appearance Models: Modeling

Volume Appearance

480

29.2.3.3 3D Active Appearance Models: Matching . . 481

29.2.3.4 Multi-view Active Appearance Models . . . 482

29.2.3.5 3D + time Active Appearance Models . . . . 484

29.3 Discussion and Conclusion

484

30 Characterization of Diffusion Anisotropy in DWI

487

Y. Chen

30.1 Introduction

487

30.2 Estimation of PDF

489

30.3 Estimation of ADC profiles

493

30.4 Conclusion

499

31 Segmentation of Diffusion Tensor Images

503

Z. Wang and B. Vemuri

31.1 Introduction

503

31.2 K-means for DTI segmentation

505

31.3 Boundary-based active contours for DTI segmentation

505

31.4 Region-based active contour for DTI segmentation

507

31.4.1 An information theoretic diffusion tensor "distance" . . 507

31.4.2 The DTI Segmentation Model

509

31.4.3 The Piecewise Constant Model for DTI Segmentation . 510

31.4.4 The Piecewise Smooth DTI Segmentation Model . . . 511

Contents

xvii

31.4.5 Experimental Results

513

31.5 Conclusion

514

32 Variational Approaches to the Estimation, Regularization and

Segmentation of Diffusion Tensor Images

517

R. Deriche, D. Tschumperle, C. Lenglet and M. Rousson

32.1 Introduction

517

32.2 Estimation of Diffusion Tensor Images

518

32.2.1 Data acquisition

518

32.2.2 Linear estimation

519

32.2.3 Variational estimation

519

32.3 Regularizationof Diffusion Tensor Images

520

32.3.1 On some non-spectral methods and their limitations . . 521

32.3.2 A fast isospectral method

521

32.4 Segmentation ofDiffusion Tensor Images

522

32.4.1 Level-set and region-based surface evolution

523

32.4.2 Multivariate Gaussian distributions as a Hnear space . . 523

32.4.3 Information-theoretic statistics between distributions . 524

32.4.4 A Riemannian approach to DTI segmentation

527

32.5 Conclusion

530

33 An Introduction to Statistical Methods of Medical Image Registra-

tion

531

L. Zollei, J. Fisher and W. Wells

33.1 Introduction

531

33.2 The Similarity Measures

532

33.2.1 Maximum Likelihood

533

33.2.2 Approximate Maximum Likelihood

535

33.2.3 KuUback-Leibler Divergence

537

33.2.4 Mutual Information and Joint Entropy

539

33.3 Conclusion

541

Bibliography

543

Bibliography

543

Preface
Abstract Biological vision is a rather fascinating domain of research. Scientists of various origins like biology, medicine, neurophysiology, engineering, mathematics, etc. aim to understand the processes leading to visual perception process and at reproducing such systems. Understanding the environment is most of the time done through visual perception which appears to be one of the most fundamental sensory abilities in humans and therefore a significant amount of research effort has been dedicated towards modelling and reproducing human visual abilities. Mathematical methods play a central role in this endeavour.
Introduction
David Marr's theory v^as a pioneering step tov^ards understanding visual perception. In his view human vision was based on a complete surface reconstruction of the environment that was then used to address visual subtasks. This approach was proven to be insufficient by neuro-biologists and complementary ideas from statistical pattern recognition and artificial intelligence were introduced to better address the visual perception problem. In this framework visual perception is represented by a set of actions and rules connecting these actions. The emerging concept of active vision consists of a selective visual perception paradigm that is basically equivalent to recovering from the environment the minimal piece information required to address a particular task of interest.
Mathematical methods are an alternative to tackle visual perception. The central idea behind these methods is to reformulate the visual perception components as optimization problems where the minima of a specifically designed objective function "solve" the task under consideration. The definition of such functions is often an ill-posed problem since the number of variables to be recovered is much larger than the number of constraints. Furthermore, often the optimization process itself is ill-posed due the non-convexity of the designed function inducing the presence of local minima. Variational, statistical and combinatorial methods are

XX

Preface

three distinct and important categories of mathematical methods in computational vision.
Variational techniques are either based on the optimization of cost functions through the calculus of variations or on the design of partial differential equations v^hose steady state corresponds to the solution of the visual perception task. Such techniques have gained significant attention over the past decade and have been used to address image restoration and enhancement, image segmentation, tracking and stereo reconstruction among other problems. The possibility to use the calculus of variations in the optimization process is the most important strength of these methods combined with the fact that one can integrate many terms and build quite complicated objective functions at the expense of converging toward local minima.
Statistical methods often consist of two stages, a learning and an execution one. Complex conditional, multi-dimensional distributions are used to describe visual perception tasks that are learnt through a training procedure. Visual perception is then formulated as an inference problem, conditional to the observations (images). One can claim that such methods are suitable to address constrained optimization problems, in particular when the subset of solutions can be well described through a conditional parametric density function. They suffer from the curse of dimensionality, e.g. in the Bayesian case when very-high dimensional integrals have to be computed.
Discrete optimization is an alternative to the continuous case often addressed through statistical and variational methods. To this end, visual perception is often redefined as a labelling procedure at the image element level according to a predefined set of plausible classes. Such a simplification often reduces the dimensionality of the problem and makes possible the design of efficient optimization algorithms. On the other hand such methods can have limited performance because of the discretization of the solution space, in particular when the solution lives in a rather continuous in-homogeneous space. One can refer to graph-based methods for addressing such tasks.
The choice of the most appropriate technique to address visual perception is rather task-driven and one cannot claim the existence of a universal solution to most of the visual perception problems. In this edited volume, our intention is to present the most promising and representative mathematical models to address visual perception through variational, statistical and combinatorial methods. In order to be faithful to the current state of the art in visual perception, a rather complete set of computational vision components has been considered starting from low level vision tasks like image enhancement and restoration and ending at complete reconstruction of scene's geometry from images.
The volume is organized in six thematic areas and thirty-three chapters presenting an overview of existing mathematical methodologies to address an important number of visual perception tasks.

Preface

xxi

Contributions & Contributors

Image reconstruction from either destroyed or incomplete data is a crucial low level task of visual perception. Local filter operators, diffusion methods as well as variational methods are among the most studied methods in the domain. The book starts with three tutorial chapters in this thematic area. The total variation method and diffusion filters as well as image decomposition in orthogonal bases, two of the most instrumental methods to address image reconstruction are presented in the first chapter. Image inpainting/completion is a more advanced problem consisting of restoring missing information in images ; it belongs to the same family and is covered in chapter 2. In the third chapter of this thematic area, an introduction to the problem as well as the most prominent techniques from the area of variational methods are presented.
Image segmentation and object extraction are of particular interest with applications in numerous domains. In its simplest instantiation the problem consists of creating an image partition with respect to some feature space, the regions being assumed to have uniform visual structure in this space. Such a problem can be solved in many ways. Labelling is an example where the objective is to assign to the local image element the most hkely hypothesis given the observation. Two chapters explore such a concept in this thematic area, the watershed transformation is one of them and combinatorial optimization through the graph-cuts paradigm is another. Evolution of curves and surfaces is an alternative method to address the same problem. Classes are represented through moving interfaces that are deforming in order to capture image regions with consistent visual properties. The snake model - a pioneering framework - is the predecessor of the methods presented. First, an overview for finding multiple contours for contour completion from points or curves in 2D or 3D images is presented using the concept of minimal paths. Then in order a method that integrate region statistics is presented within deformable models leading to a new class of deformable shape and texture models. Use of prior knowledge is important within the segmentation process and therefore in the next chapter the design of shape priors for variational regionbased segmentation is presented. Segmentation through the propagation of curves through the level set method is an established technique to grouping and object extraction Therefore, methods to address model-free as well as model-based segmentation are part of this thematic area. Last, but not least, a stochastic snake model based the theory of interacting particle systems and hydrodynamic limits is presented as a new way of evolving curves as a possible alternative to level set methods.
Representing and understanding structures is an essential component of biological vision, often used as a basis for high level vision tasks. Therefore, a thematic area dedicated to shape modelling and registration is present in this volume. Shape representations of various form are explored while at the same time the notions of establishing correspondences between different structures representing the same object are presented as well as methods recovering correspondences between shapes and images.

xxii

Preface

Motion analysis is a fundamental area of computational vision and mostly consists of two problems, estimating correspondences between images and being able to track objects of interest in a sequence of images. Optical flow estimation can be addressed in different ways. In this thematic area we explore the use of parametric motion models as well as the estimation of dense correspondences between images. Furthermore, we present a compendium of existing methods to detect and track objects in a consistent fashion within several frames as well as variational formulations to segment images and track objects in several frames. Understanding the real 3D motion is a far more complicated task of computational vision in particular when considering objects that do exhibit a number of articulations. Human motion capture is an example that is presented in this thematic area. We conclude with methods going beyond objects that are able to account, describe and reproduce the dynamics of structured scenes.
Stereo reconstruction is one of the best studied tasks in high level vision. Understanding and reproducing the 3D geometry of a scene is a fundamental component of biological vision. In this thematic area the shape from shading problem i.e. that of recovering the structure of the scene from one single image is first addressed. Different methods exploring the use of multiple cameras to recover 3D from images are then presented, based on differential geometry, variational formulations and combinatorial optimization. The notion of time and dynamic behaviour of scenes is also addressed where the objective is to create 3D temporal models of the evolving geometry.
Medical image analysis is one of the most prominent application domains of computer vision and in such a constrained solution space one can develop methods that can better capture the expected form of the structures of interest. Regularization, segmentation, object extraction and registration are the tasks presented in this thematic area. Model-free combinatorial methods that aim to recover organs of particular interest, statistical methods that aim to capture the variation of anatomical structures, and variational methods that aim to recover and segment smooth vectorial images are presented. Last, but not least a comprehensive review of statistical methods to image registration is presented, a problem that consists of recovering correspondences between different modalities measuring the same anatomical structure.
In order to capture the spectrum of the different methods and present an overview of mathematical methodologies in computational vision a notable number of contributors was invited to complete such an effort. Eighty-three contributors from the academic and the industrial world, from nine different countries and thirty-eight institutions have participated in this effort. The final outcome consists of 6 thematic areas, 33 chapters, 625 pages and 929 references.

N. Paragios, Y. Chen & O. Faugeras

List of Contributors
Agrawal, Motilal Artificial Intelligence Center SRI International, Menlo Park, USA mailto:agrawal@ai.sri.com http ://www. ai. sri.com/people/agrawal/
van Assen, Hans Division of Image Processing, Department of Radiology Leiden University, Leiden, Netherlands mailto:H.C.van_ Assen@lumc.nl
Aubert, Gilles Department of Mathematics Universite de Nice/Sophia Antipolis, France mailto:gaubert@math.unice.fr http://mathl .unice.fr/~gaubert/
Barlaud, Michel Laboratoire 13 S CNRS-Universite de Nice/Sophia Antipolis, France mailto:barlaud@i3s.unice.fr http://www.i3s.unice.fr/'^barlaud/
Barron, Carlos Department of Computer Science University of Houston, Houston, USA mailto:cbarron@uh.edu
Bertalmio, Marcelo Departament de Tecnologia Universitat Pompeu Fabra, Barcelona, Spain mailto:marcelo.bertalmio@upf.edu

xxiv
http://www.tecn.upf.es/~mbertalmio
Bergtholdt, Martin Department of Mathematics & Computer Science University of Mannheim, Germany mailto:bergtholdt@uni-mannheim.de http://www.cvgpr.uni-mannheim.de/
Blake, Andrew Microsoft Research Cambridge, UK mailto:ablake@microsoft.com http://www.research.microsoft.com/~ablake
Boykov, Yuri Departament of Computer Science University of Western Ontario, Canada mailto:yuri@csd.uwo.ca http://www.csd.uwo.ca/faculty/yuri/
Brox, Thomas Faculty of Mathematics and Computer Science Saarland University, 66041 Saarbrucken, Germany mailto:brox@mia.uni-saarland.de http://www.mia.uni-saarland.de/brox/
Bruckstein, Alfred M. Computer Science Department Technion, Haifa, Israel mailto:freddy@cs.technion.ac.il
Caselles, Vicent Departament de Tecnologia Universitat Pompeu Fabra, Barcelona, Spain mailto:vicent.caselles@upf.edu http://www.iua.upf.es/~vcaselles/
Chan, Tony Department of Mathematics University of California at Los Angeles, USA mailto:chan@math.ucla.edu http://www.math.ucla.edu/~chan
Chen, Ting Department of Radiology NYU Medical School, New York, USA

List of Contributors

List of Contributors

xxv

mailto:ting.chen@med.nyu.edu

Chen, Yunmei Department of Mathematics University of Florida, Gainesville, USA mailto:yun@math.ufl.edu http://www.math.ufl.edu/~yun/

Cohen, Laurent CEREMADE Universite Paris IX Dauphine, Paris, France mailto:cohen@ceremade.dauphine.fr http://ww^w.ceremade.dauphine.fr/~cohen

Cremers, Daniel Imaging & Visualization Department Siemens Corporate Research, Princeton, NJ, USA mailto:daniel.cremers@scr.siemens.com http://www.cs.ucla.edu/~cremers

Davis, Larry Department of Computer Science University of Maryland, College Park, USA mailto:lsd@cs.umd.edu http://cvl.umiacs.umd.edu/users/lsd/

Deriche, Rachid I.N.R.I.A. Sophia Antipolis, France mailto:Rachid.Deriche@inria.fr http://www-sop.inria.fr/odyssee/team/Rachid.Deriche/

Doretto, Gianfranco Computer Science Department University of California at Los Angeles, USA mailto:doretto@cs.ucla.edu http://www.cs.ucla.edu/~doretto/

Esedoglu, Selim Department of Mathematics University of California at Los Angeles, USA mailto:esedoglu@math.ucla.edu http://www.math.ucla.edu/~esedoglu

Faugeras, Olivier I.N.R.I.A. Sophia Antipohs, France

xxvi

List of Contributors

mailto:01ivier.Faugeras@inria.fr http://www-sop.inria.fr/odyssee/team/01ivier.Faugeras
Fisher III, John Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, USA mailto:fisher@ai.mit.edu http://www.ai.mit.edu/people/fisher/
Fleet, David Department of Computer Science University of Toronto, Toronto, Canada mailto:fleet@cs.toronto.edu http://www.cs.toronto.edu/~fleet/
Frangi, Alejandro Department of Technology Pompeu Fabra University, Barcelona, Spain mailto:alejandro.frangi@upf.edu http://www.tecn.upf.es/~afrangi/

Grady, Leo Imaging and Visualization Department Siemens Corporate Research, Princeton, USA mailto:leo.grady@siemens.com

Guo, Hongyu Department of Computer, Information Science and Engineering University of Florida, Gainesville, USA mailto:hguo@cise.ufl.edu http://www.cise.ufl.edu/~hguo

Hare, Gloria Departament de Tecnologia Universitat Pompeu Fabra, Barcelona, Spain mailto:gloria.haro@upf.edu http://v^rww.tecn.upf.es/~gharo
Herbulot, Ariane Laboratoire 13 S CNRS-Universite de Nice/Sophia Antipolis, France mailto:herbulot@i3s.unice.fr http://www.i3s.unice.fr/~herbulot/

Huang, Xiaolei

List of Contributors

xxvii

Division of Computer and Information Sciences Rutgers, the State University of New Jersey, New Brunswick, USA mailto:xiaolei@paul.rutgers.edu http://www.research.rutgers.edu/~xiaolei/

Jehan-Besson, Stephanie Laboratoire GREYC-Image Ecole Nationale Superieure d'Ingenieurs de Caen, France mailto:stephanie.jehan@greyc.ensicaen.fr http ://www.greyc .ensicaen. fr/~j ehan

Joshi, Sarang Department of Radiation Oncology and Biomedical Engineering University of North Carolina, Chapel Hill, USA mailto:sjoshi@unc.edu http://www.cs.unc.edu/~joshi

Joshi, Shantanu Department of Electrical Engineering Florida State University, Tallahassee, USA mailto:joshi@eng.fsu.edu

Kakadiaris, loannis Department of Computer Science University of Houston, Houston, USA mailto: ikakadia@central .uh. edu http://www.vcl.uh.edu/~ioannisk/

Kaziska, Dave Department of Statistics Florida State University, Tallahassee, USA mailto:kaziska@stat.fsu.edu

Keriven, Renaud Departement d'Informatique Ecole Normale Superieure, Paris, France mailto:Renaud.Keriven@ens.fr http://cermics.enpc.fr/~keriven/home.html

Kolmogorov, Vladimir Microsoft Research Cambridge, UK mailto:vnk@microsoft.com http://www.research.microsofl.com/~vnk

Lenglet, Christophe

xxviii

List of Contributors

I.N.R.I.A. Sophia Antipolis, France mailto:clenglet@sophia.inria.fr http://www-sop.inria.fr/odyssee/team/Christophe.Lenglet/
Lelieveldt, Boudewijn Division of Image Processing, Department of Radiology Leiden University Medical Center, Leiden, Netherlands mailto:B.Lelieveldt@lumc.nl
Markussen, Bo Department of Computer Science University of Copenhagen, Denmark mailto:boma@diku.dk http: //www.bomar. dk/

Metaxas, Dimitris Division of Computer and Information Sciences Rutgers, the State University of New Jersey, New Brunswick, USA mailto:dnm@cs.rutgers.edu http://www.cs.rutgers.edu/~dnm/

Meyer, Fernand Centre de Morphologic Mathematique Ecole des Mines de Paris, Paris, France mailto:femand.meyer@cmm.ensmp.fr http://cmm.ensmp.fr

Mitchell, Steven The University of Iowa, Iowa City, USA mailto:steve@componica.com

Mittal, Anurag Real-time Vision and Modeling Department Siemens Corporate Research, Princeton, USA mailto:anurag.mittal@siemens.com http://www.umiacs.umd.edu/'^ anurag

Mrazek, Pavel Upek, Husinecka 7, Praha 3, Czech Republic mailto:pavel.mrazek@upek.com

Nain, Delphine Departments of Electrical and Computer and Biomedical Engineering Georgia Institute of Technology, Atlanta, USA mailto:delfin@cc.gatech.edu

List of Contributors

xxix

http://www.bme.gatech.edu/groups/bil/

Nielsen, Mads Department of Innovation IT University of Copenhagen, Denmark mailto:malte@itu.dk http://www.itu.dk/people/malte

Ordas, Sebastian Department of Technology Pompeu Fabra University, Barcelona, Spain mailto:sebastian.ordas@upf.edu

Paragios, Nikos C.E.R.T.I.S. Ecole Nationale des Fonts et Chaussees, Champs sur Mame, France mailto:nikos.paragios@certis.enpc.fr http://www.enpc.fr/certis/people/paragios.html

Park, Frederick Department of Mathematics University of California at Los Angeles, USA mailto: fpark@math.ucla. edu http://www.math.ucla.edu/~fpark

Pollefeys, Marc Department of Computer Science University of North Carolina, Chapel Hill, USA mailto:marc@cs.unc.edu http ://www.cs.unc .edu/'^marc/

Pons, Jean-Philippe C.E.R.T.LS. Ecole Nationale des Fonts et Chaussees, Champs sur Mame, France mailto:Jean-Philippe.Fons@certis.enpc.fr http://www.enpc.fr/certis/people/pons.html

Prados, Emmanuel I.N.R.I.A. Sophia Antipolis, France mailto:Emmanuel.Frados@sophia.inria.fr http://www-sop.inria.fr/odyssee/team/Emmanuel.Frados/

Rangarajan, Anand Department of Computer, Information Science and Engineering University of Florida, Gainesville, USA

XXX

List of Contributors

mailto:anand@cise.ufl.edu http://www.cise.ufl.edu/'^anand

Reiber, Johan H.C. Department of Radiology Leiden University Medical Center, Leiden, the Netherlands mailto:J.H.C.Reiber@lumc.nl http://www.lkeb.nl

Rousson, Mikael Imaging and Visualization Department Siemens Corporate Research, Princeton, USA mailto:mikael.rousson@scr.siemens.com

Sapiro, Guillermo Department of Electrical and Computer Engineering University of Minnesota, Minneapolis, USA mailto:guille@ece.umn.edu http://www.ece.umn.edu/users/guille/

Schnorr, Christoph Department of Mathematics & Computer Science University of Mannheim, Germany mailto:schnoerr@uni-mannheim.de http://www.cvgpr.uni-mannheim.de/

Soatto, Stefano Computer Science Department University of California at Los Angeles, USA mailto:soatto@cs.ucla.edu http://www.cs.ucla.edu/~soatto/

Sonka, Milan Dept. of Electrical and Computer Engineering The University of Iowa, Iowa City, USA mailto:milan-sonka@uiowa.edu http://www.engineering.uiowa.edu/~sonka/
Srivastava, Anuj Department of Statistics Florida State University, Tallahassee, USA mailto:anuj@stat.fsu.edu http://stat.fsu.edu/~anuj

Steidl, Gabriele

List of Contributors

xxxi

Faculty of Mathematics and Computer Science University of Mannheim, Mannheim, Germany mailto:steidl@math.uni-mannheim.de http://kiwi.math.uni-mannheim.de/

Stewart, Charles Department of Computer Science Rensselaer Polytechnic Institute, Troy, USA mailto:stewart@cs.rpi.edu http://www.cs.rpi.edu/~stewart

Sun, Yiyong Imaging and Visualization Department Siemens Corporate Research, Princeton, USA mailto:yiyong,sun@siemens.com

Szeliski, Richard Microsoft Research, Redmond, USA mailto:szeliski@microsoft.com http://www.research.microsoft.com/~szeliski/

Tannenbaum, Allen Departments of Electrical and Computer and Biomedical Engineering Georgia Institute of Technology, Atlanta, USA mailto:tannenba@bme.gatech.edu http://www.bme.gatech.edu/groups/bil/

Tschumperle, David GREYC - UMR CNRS 6072 Centre National de la Recherche Scientifique (CNRS), Caen, France mailto:David.Tschumperle@greyc.ensicaen.fr http://www.greyc.ensicaen.fr/~dtschump/

Unal, Gozde Intelligent Vision and Reasoning Siemens Corporate Research, Princeton, USA mailto:gozde.unal@siemens.com

Veksler, Olga Departament of Computer Science University of Western Ontario, Canada mailto:olga@csd.uwo.ca http://www.csd.uwo.ca/faculty/olga/

Vemuri, Baba

xxxii

List of Contributors

Department of Computer, Information Science and Engineering Univiversity of Florida, Gainesville, USA mailto:vemuri@cise.ufl.edu http://www.cise.ufl.edu/~vemuri
Wang, Zhizhou Imaging and Visualization Department Siemens Corporate Research, Princeton, USA mailto:zhizhou.wang@siemens.com

Weickert, Joachim Faculty of Mathematics and Computer Science Saarland University, Saarbrucken, Germany mailto:weickert@mia.uni-saarland.de http://www.mia.uni-saarland.de/weickert/
Welk, Martin Faculty of Mathematics and Computer Science Saarland University, Saarbrucken, Germany mailto:welk@mia.uni-saarland.de http://www.mia.uni-saarland.de/welk/

Weiss, Yair School of Computer Science and Engineering The Hebrew University of Jerusalem, Jerusalem, Israel mailto:yweiss@cs.huji.ac.il http://www.cs.huji.ac.il/'^yweiss/
Wells III, William Department of Radiology Harvard Medical School and Brigham and Women's Hospital, Boston, USA mailto:sw@bwh.harvard.edu http://splweb.bwh.harvard.edu:8000/pages/ppl/sw/homepage.html
Williams, James Imaging and Visualization Department Siemens Corporate Research, Princeton, USA mailto:jimwiUiams@siemens.com
Wilson, Dave Department of Mathematics University of Florida, Gainesville, USA mailto:dcw@math.ufl.edu

List of Contributors

xxxiii

http://www.math.ufl.edu/~dcw/

Yezzi, Anthony Departments of Electrical and Computer and Biomedical Engineering Georgia Institute of Technology, Atlanta, USA mailto:ayezzi@ece.gatech.edu http://www.ece.gatech.edu/profiles/ayezzi/
Yip, Andy Department of Mathematics University of California at Los Angeles, USA mailto:mhyip@math.ucla.edu http://www.math.ucla.edu/~mhyip

Zabih, Ramin Department of Computer Science Cornell University, Ithaca, USA mailto:rdz@cs.comell.edu http://www.cs.comell.edu/~rdz

Zeitouni, Ofer School of Mathematics University of Minnesota, Minneapolis, USA mailto:zeitouni@math.umn.edu

Zollei, Lilla Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, USA mailto:lzollei@csail.mit.edu http://people.csail.mit.edu/people/lzollei/

Zucker, Steven Department of Computer Science and Program in Applied Mathematics Yale University, New Haven, USA mailto: Steven.zucker@yale. edu http://www.cs.yale.edu/homes/vision/zucker/steve.html

Parti
Image Reconstruction

Chapterl
Diffusion Filters and Wavelets: What Can They Learn from Each Other?
J. Weickert, G. SteidI, P. Mrazek, M. Welk, and T. Brox
Abstract Nonlinear diffusion filtering and wavelet shrinkage are two methods that serve the same purpose, namely discontinuity-preserving denoising. In this chapter we give a survey on relations between both paradigms when spacediscrete or fully discrete versions ofnonlinear diffusion filters are considered. For the case of space-discrete diffusion, we show equivalence between soft Haar wavelet shrinkage and total variation (TV) diffusion for 2-pixel signals. For the general case of iV-pixel signals, this leads us to a numerical scheme for TV diffusion with many favourable properties. Both considerations are then extended to 2-D images, where an analytical solution for 2 x 2 pixel images serves as building block for a wavelet-inspired numerical scheme for TV diffusion. When replacing space-discrete diffusion byfiiUydiscrete one with an explicit time discretisation, we obtain a general relation between the shrinkagefiinctionof a shift-invariant Haar wavelet shrinkage on a single scale and the diffusivity of a nonlinear diffusion filter. This allows to study novel, diffusion-inspired shrinkagefiinctionswith competitive performance, to suggest new shrinkage rules for 2-D images with better rotation invariance, and to propose coupled shrinkage rules for colour images where a desynchronisation of the colour channels is avoided. Finally we present a new result which shows that one is not restricted to shrinkage with Haar wavelets: By using wavelets with a higher number of vanishing moments, equivalences to higher-order diffusion-like PDEs are discovered.
1.1 Introduction
Signal and image denoising is a field where one often is interested in removing noise without sacrificing important structures such as discontinuities. To this end, a large variety of nonlinear strategies has been proposed in the literature including

Weickert, Steidl, Mrazek, Welk & Brox

1

Tt 1 •1 jE^klr^^V

JflH
\

,m
TT 1

Figure 1.1. (a) Left: Original image with additive Gaussian noise, (b) Middle: Result after shift invariant soft wavelet shrinkage, (c) Right: Result after nonlinear diffusion filtering with total variation diffiisivity.

wavelet shrinkage [275] and nonlinear diffusion filtering [642]; see Figure 1.1. The goal of this chapter is to survey a number of connections between these two techniques and to outline how they can benefit from each other.
While many publications on the connections between wavelet shrinkage and PDE-based evolutions (as well as related variational methods) focus on the analysis in the continuous setting (see e.g. [49, 114,161, 163, 568]), significantly less investigations have been carried out in the discrete setting [214]. In this chapter we give a survey on our contributions that are based on discrete considerations. Due to the lack of space we can only present the main ideas and refer the reader to the original papers [584, 585, 586, 760, 882] for more details.
This chapter is organised as follows: In Section 1.2 we start with briefly sketching the main ideas behind wavelet shrinkage and nonlinear diffusion filtering. Afterwards in Section 1.3 we focus on relations between both worlds, when we restrict ourselves to space-discrete nonlinear diffusion with a total variation (TV) diffiisivity and to soft Haar wavelet shrinkage. Section 1.4 presents additional relations that arise from considering fully discrete nonlinear diffusion with arbitrary diffusivities, and Haar wavelet shrinkage with arbitrary shrinkage functions. In Section 1.5 we present a new result that generalises these considerations to higherorder diffusion-like PDEs and shrinkage with wavelets having a higher number of vanishing moments. The chapter is concluded with a summary in Section 1.6.

1.2 Basic Methods
1.2.1 Wavelet Shrinkage
Wavelet shrinkage has been made popular by a series of papers by Donoho and Johnstone (see e.g. [274, 275]). Assume we are given some discrete 1-D signal / = {fi)iez that we may also interpret as a piecewise constant function. Then the discrete wavelet transform represents / in terms of shifted versions of a dilated scaling function ip, and shifted and dilated versions of a wavelet function X/J. In

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

5

case of orthonormal wavelets, this gives

where ipl{s) := 2~-^/^'0(2~"^s - i) and where (•, •) denotes the inner product in L2(M). If the measurement / is corrupted by moderate white Gaussian noise, then this noise is contained to a small amount in all wavelet coefficients (/, V4\ while the original signal is in general determined by a few significant wavelet coefficients [540]. Therefore, wavelet shrinkage attempts to eliminate noise from the wavelet coefficients by the following three-step procedure:
1. Analysis: Transform the noisy data / to the wavelet coefficients d'l = (/, ipl) and scaling function coefficients cf = (/, cpf) according to (1.1).
2. Shrinkage: Apply a shrinkage function SQ with a threshold parameter 0 to the wavelet coefficients, i.e., S0{d{) = S0{{f, tpf)).
3. Synthesis: Reconstruct the denoised version u of f from the shrunken wavelet coefficients:

u:=J2{f,^7)^7+ E E^««/'^i))^''- ('-2)

iez

j=-oo iez

In this paper we pay particular attention to Haar wavelets, well suited for piece-

wise constant signals with discontinuities. The Haar wavelet and Haar scaling

functions are given respectively by

H^) = l [ o , i ) - l [ i , i ) .

(1-3)

^{x) = l[o,i)

(1.4)

where l[a,b) denotes the characteristic function, equal to 1 on [a, 6) and zero everywhere else. In the case of the so-called soft wavelet shrinkage [274], one uses the shrinkage function

1.2.2 Nonlinear Diffusion Filtering

The basic idea behind nonlinear diffusion filtering [642, 870] in the 1-D case is to obtain a family u{x, t) of filtered versions of a continuous signal f{x) as the solution of a suitable diffusion process

^t = (5'(|^a:|)Wx).x

(1.6)

with / as initial condition,

^(x,0) = /(x)

6

Weickert, Steidl, Mrazek, Welk & Brox

and reflecting boundary conditions. Here subscripts denote partial derivatives, and the diffusion time t is a simplification parameter: Larger values correspond to more pronounced filtering.
The diffusivity g{\ux\) is a nonnegative function that controls the amount of diffusion. Usually, it is decreasing in \ux\. This ensures that strong edges are less blurred by the diffusion filter than low-contrast details. In this chapter, the total variation (TV) diffusivity

9{\s\) = ^

(1.7)

plays an important role, since the resulting TV diffusion [27,272] does not require to specify additional contrast parameters, leads to scale invariant filters, has finite extinction time, interesting shape-preserving qualities, and is equivalent to TV regularisation [695] in the 1-D setting; see the references in [882] for more details.
Unfortunately, TV diffusion is not unproblematic in practice: In corresponding numerical algorithms the unbounded diffusivity requires infinitesimally small time steps or creates very ill-conditioned linear systems. Therefore, TV diffusion is often approximated by a model with bounded diffusivity:

This regularisation, however, may introduce undesirable blurring effects and destroy some of the favourable properties of unregularised TV diffusion.

1.3 Relations for Space-Discrete Diffusion
In this section we study connections between soft Haar wavelet shrinkage and nonlinear diffusion with TV diffusivity in the space-discrete case. This allows us to find analytical solutions for simple scenarios. They are used as building blocks for numerical schemes for TV diffusion.

1.3.1 Equivalence for Two-Pixel Signals
We start by considering wavelet shrinkage of a two-pixel signal ( / o , / i ) in the Haar basis [760]. Its coefficients with respect to the scaling function ip = ( 7 2 ' 75) ^^^ ^^® wavelet V^ = ( - ^ , ^ ) are given by

_ /o + /i

,

fo-fi

(1.9)

x/2 '

V2

Soft thresholding of the wavelet coefficient yields

So{d)-^

0

if \d\<0,

^^'^^^

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

7

leading to the filtered signal {UQ^UI) with

I

(/o + / i ) / 2

else,

^^

I

(/o + / i ) / 2

else.

^^

On the other hand, space discrete TV diffusion of a two-pixel signal with reflecting boundary conditions and grid size 1 creates the dynamical system

UQ = sgn{ui-uo) ill = -sgn{ui-uo)

(1-13) (1.14)

with initial conditions UQ{Q) = /o and ui{0) = / i . The dot denotes differentiation with respect to time. It is easy to verify that this system with discontinuous right hand side has the unique analytical solution

„ tt) _ f fo + tsgn{fi-fo) " ° ^ ^ ~ 1 (/o + / i ) / 2

if

t<\h-fo\/2,

else,

^^•^^>

"^^*^ - I (/o + / i ) / 2

else.

^^'^^^

Interestingly, this is equivalent to soft Haar wavelet shrinkage with threshold 6 = \/2t. Moreover, we observe that a finite extinction time is obvious in the two-pixel model and that no problems with degenerated diffusivities appear [760].

1.3.2 A Wavelet-Inspired Schemefor TV Diffusion of Signals
Let us now investigate if we can also benefit from the 2-pixel equivalences in the case of general discrete 1-D signals with N pixels. To this end, we perform a wavelet decomposition on the finest scale only. Haar wavelets create natural two-pixel pairings, but unfortunately, their shrinkage is not shift invariant. As a remedy, Coifman and Donoho have proposed to apply cycle spinning [213]: On one hand, shrinkage is performed on the original signal. In parallel to this the signal is shifted by 1 pixel, shrinkage is performed, and then the result is shifted back. Averaging both filtered signals creates a process that is shift invariant by construction.
Interestingly this procedure does also inspire a novel numerical scheme for TV diffusion. It uses the analytical solution of the two-pixel model as a building block. With the two-pixel model, TV diffusion with time step size 2r is performed on all pixel pairs (^X22,2x2*4-1 )• In parallel we perform TV diffusion on all pixel pairs {u2i-i,U2i). Averaging both results leads to the following numerical scheme for

Weickert, Steidl, Mrazek, Welk & Brox

5o[

001-

sof

^

/ ^:

| u ^~-,1 .,-J ^'
(«

500 1000 1900 2000 2S00

soh

"*[

J ,/

- - ,/

•h [ L J

\ soL
r fl 4LJ ^"oo[

y-

1S0O 2000 2900 3000 3900 4000

1900 2000 2900 3000

Figure 1.2. (a) Top left: Original signal without noise, (b) Top right: With additive Gaussian noise, SNR=8 dB. (c) Bottom left: Result with two-pixel scheme. SNR = 24.5 dB. (d) Bottom right: Result with classical regularised scheme. SNR = 24.6 dB. From [760].

TVdifaision[760]: ,.fc+i

sgn {u'k. - < ) min( 1, —\u:ik+1

- ^ Sgn {u^ - uti) min h , —\u^ - ^ t i l j , (1-17)

where the upper index k denotes the time level kr, and h is the spatial grid size. Although this scheme is explicit, it is even absolutely stably since it is based on a linear combination of analytical two-pixel interactions that satisfy a maximum-minimum principle. Moreover, it can be shown that the scheme is also conditionally consistent to the continuous TV diffusion [760]. It should be noted that it does not require any regularisation of the diffusivity such as (1.8), and hence does not suffer from corresponding dissipative artifacts at edges. In Figure 1.2 it is shown that it is a competitive alternative to conventional schemes based that approximate regularised TV diffusion.

1.3.3 Generalisations to Images
Interestingly, the considerations in Subsections 1.3.1 and 1.3.2 can be generalised to the 2-D setting [882]. By considering an image with 2 x 2 pixels, one shows that soft Haar wavelet shrinkage and space-discrete TV diffusion are equivalent by deriving the same analytical solution for both processes. In order to use this 4-pixel solution as a building block for a numerical scheme for 2-D TV diffusion, we consider the four 2 x 2 cells containing some pixel (?', j ) . By computing their

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

Figure 1.3. (a) Left: Original image, 93 x 93 pixels, (b) Middle: Standard explicit scheme for regularised TV diffusion (e = 0.01, r = 0.0025, 10000 iterations), (c) Right: Same with four-pixel scheme without regularisation (r — 0.1,250 iterations). Note that 40 times larger time steps are used. From [882].
analytical solutions and averaging the results, we obtain a v^avelet-inspired numerical scheme for 2-D TV diffusion. In the same v^ay as its 1-D counterpart, it is explicit, absolutely stable, conditionally consistent, and does not require any regularisation of the singular TV diffusion equation. Compared to classical exphcit discretisations based on regularised TV diffusion, it creates sharper edges, even when significantly larger time step sizes are used; see Figure 1.3.

1.4 Relations for Fully Discrete Diffusion
The previous section focused on space-discrete TV diffusion and soft Haar wavelet shrinkage. This restriction allowed us to derive analytical solutions for both paradigms. In order to obtain additonal connections let us now investigate fully discrete nonlinear diffusion with arbitrary difflisivities and Haar wavelet shrinkage with general shrinkage functions.

1.4.1 Diffusion-Inspired Shrinkage Functions

Let us consider a discrete signal {fi)iez- It is easily seen that one cycle of shiftinvariant Haar wavelet shrinkage on a single level creates a filtered signal {ui)i^z with

fi-l-^2fi-\- fi^l y/2

ffi-fi+i

"• = 4 + x^^i-7r-

v/2^ ffi-i-fi

(1.18)

On the other hand, the first iteration of an explicit (Euler forward) scheme for a nonlinear diffusion filter with initial state / , time step size T and spatial step size

10

Weickert, Steidl, Mrazek, Welk & Brox

Figure 1.4. (a) Top: Four popular shrinkage functions: soft, garrote, firm, and hard shrinkage, (b) Bottom: Corresponding difiusivities. From [585].

1 leads to Ui - fi = P ( l / ^ + l - / i l ) ( / ^ + l - / ^ ) " P(l/f " / t 11) ( / ' " / ' - l ) ,
which can be rewritten as

O'l^)

+ (/i-/i+i)

(•^-rg{\fi-fi^i\)

(1.20)

Comparing (1.18) and (1.20) shows that both methods are equivalent if

N/2
Se {T^-

r9{\s\)

(1.21)

This formula states a general correspondence between a shrinkage function Se of a shift-invariant single scale Haar wavelet shrinkage and the diffusivity g of an explicit nonlinear diffusion scheme [585]. It does not only allow to reinterpret a number of shrinkage strategies as nonlinear diffusion filters (Figure 1.4), it also leads to novel, diffusion-inspired shrinkage functions (Figure 1.5). Interestingly, some of these diffusion-inspired shrinkage functions turn out to belong to the ones with the best denoising capabilities [585]. A detailed analysis of this connection in terms of extremum principles, monotonicity preservation and sign stability can be found in [586].

L4.2 Wavelet Shrinkage with Improved Rotation Invariance
In order to extend our results from 1-D signals to 2-D greyscale images, we have to specify the 2-D Haar Wavelet transform first. It is based on a lowpass filter L with coefficients (755 :;^) ^^^ a highpass filter H with coefficients (:;^5 - 7 5 ) Applying the 1-D filters L and H altematingly in x and y direction gives a 2-D

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

11

Charbormier diHusivity

WeickertdiHusivity

Figure 1.5. (a) Top: Four popular diffusivities: linear, Charbonnier, Perona-Malik, and
1 11 1• Weickert difflisivity. (b) Bottom: Corresponding shrinkage functions. From [585]. ftlB f^^SS^S'St^iMjii^B^^^B

Figure 1.6. (a) Left: Original image, (b) Right: Thefirstthree levels of a 2-D Haar wavelet decomposition.

Haar wavelet decomposition with the following structure:

,'+1 == L{x)^L[y)^v\

(1.22)

i-"'= - L{x)^H{y)^v\ i^' ^- H{x)^ L{y)^v\
i+i ,= H{x) * H{y) * v^
xy

(1.23) (1.24) (1.25)

with v^ := f. Figure 1.6 illustrates this principle. The basic idea behind classical 2-D wavelet shrinkage is now to shrink all
wavelet coefficients Wy, Wx and Wxy separately according to their magnitude. If shift invariance is required, one averages the results for the 4 shift possibilities. However, even in this case, one usually observes a severe lack of rotation invariance.

12

Weickert, Steidl, Mrazek, Welk & Brox

Figure 1.7. (a) Left: original images, (b) Middle: reconstruction after iterated shift invariant hard wavelet shrinkage, (c) Right: reconstruction by a diffusion-inspired wavelet shrinkage with much better rotation invariance. From [584].

In order to address this problem, let us investigate 2-D nonlinear diffusion filtering. In its isotropic variant with a scalar-valued diffusivity [642], it is based on the rotationally invariant equation

ut = diw{g{\Vu\)VTi)

(1.26)

In a similar way as in the 1-D situation, one can now consider explicit discretisations and relate the difiusivities to shrinkage functions for shift invariant Haar wavelet shrinkage. In contrast to classical shrinkage where the wavelet coefficients are shrunken separately, this leads to novel shrinkage rules where the wavelets are coupled [584], e.g.

5 K ) - w,(^l-4Tg(^^wl+wl + 2wly)y

(1.27)

S{wy) = Wy{l-4Tg(^^wl+wl-^2wly)),

(1.28)

S{w,y) = w^y ( l - 4 r ^ (^yjwl + ^ 2 4 . 2 ^ 2 J ^ ^ (129)

Because of the rotation invariance of the nonlinear diffusion equation, one can expect that these shrinkage rules lead to a significantly better realisiation of rotation invariance than classical 2-D wavelet shrinkage. These expectations are confirmed by the experiments in Figure 1.7.

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

13

Figure 1.8. (a) Left: Zoom into an original image, (b) Middle: After classical wavelet shrinkage without coupling the RGB channels, (c) Right: Wavelet shrinkage with diffusion-inspired channel coupling.

1.4.3 Diffusion-Inspired Wavelet Shrinkage of Colour Images
While we have investigated diffusion-inspired shrinkage of greyscale images in the previous section, let us nov^ turn our attention to colour images. In this case wavelet shrinkage is frequently applied such that the different colour channels (e.g. RGB or YUV) are shrunken separately. This can result in a lack of synchronisation that creates artifacts at colour edges.
For nonlinear diffusion filtering of colour images, one often uses a process with a joint diffiisivity that steers the evolution of all three channels [344]. In the continuous setting such an evolution has the structure

l/2\ att/i = d i v ( ^ ( ( ^ | V n , f ) )v^^,)

(1.30)

j=i

where the index i specifies the colour channel. By considering an explicit discretisation and relating it to wavelet shrinkage, we end up with shrinkage rules where all channels are coupled. Figure 1.8 illustrates that this diffusion-inspired shrinkage of colour images leads to a more convincing behaviour at edges where all channels remain synchronised.

1.5 Wavelets with Higher Vanishing Moments
Up to now we have only considered relations between Haar wavelet shrinkage and nonlinear diffusion with diffusivities depending on first order derivatives. In this section, we will see that there exists also a relation between one step of translation invariant wavelet shrinkage with wavelets having m>\ vanishing moments and explicit difference schemes of diffusion-like equations whose diffiisivities include m-th order derivatives. To our knowledge these relations have not been considered in the literature before.
For the sake of simplicity, we restrict our attention to the periodic setting, i.e., in the following all indices are taken modulo N. We are concerned with wavelet

14

Weickert, Steidl, Mrazek, Welk & Brox

filters /i* := (/IQ, .. •, ^M^-l)» ^ = 1? 2 having the perfect reconstruction property

/Mo-l

Mi-1

\

\

fc=0

A;=0

/

Moreover, we assume that h^ has m > 1 vanishing moments:

Mi-i
J2 k^'hl = 0, r - 0 , . . . , m - l ,

Mi-1
^ / . - h ^ = 7m ^ 0.

(1.32)
(1.33)

Examples of such filters are for m = 1 the Haar filter pair
/.0:=-L(U), .-=i=(l,-l)
with 7i = —1/\/2, and for m = 2 the Daubechies filter pair h^ := ^ ( l + \ / 3 , 3 + v ^ , 3 - \ / 3 , 1 - V ^ ) ,

(1.34) (1.35)

h^ := - ^ ( - 1 + A/3, 3 - \ / 3 , - 3 - \ / 3 , l + \ / 3 ) (1.36)

with 72 = y/^/y/2. Then the three steps of wavelet shrinkage applied to the signal / '= (/o,.. •, JN-I) read as follows:

• Analysis step: For j = 0 , . . . , AT — 1, we compute

Mo-l

iV-l

c, := Yl ^y^+J = E ''Ufk'

(1-37)

Mi-1

N-1

• Shrinkage step: For j = 0 , . . . , AT — 1 we shrink the highpass coefficients dj as 5^(6/^), J =: 0 , . . . , TV - 1.

• Synthesis step: For jf = 0 , . . . , TV — 1, we compute

. /Mo-l

Mi-1

\

\ k=0

k=0

I

Assume now that the samples /^ := fikh) with h := \/N were taken from a sufficiently smooth periodic fiinction with period 1. Then we obtain by the Taylor expansion that

fkM = E ^-^f^'Hlh) + 0{h"^+').
r=0

(1.40)

Diffusion Filters and Wavelets: What Can They Learn from Each Other?

Since h^ has m vanishing moments, it follovv^s with (1.38) that

m J J.

Ml—I

r=0 •

fc=0

ml Thus,

f^'^'Hlh) = - ^ d t + 0{h).

Similarly, we conclude that

x-'*^!

15
(1.41) (1.42)

Let us now consider a higher-order diffusion-like equation with periodic boundary conditions:

ut = ( ( p ( | u ( - ) | ) u ( - ) ) ^ " \

(1.44)

u{x,0) - / ( x ) ,

Xr) (0)

.(r) (1),

r = 0,...,2m-l.

(1.45) (1.46)

We approximate the inner and outer m-th derivatives by (1.42) and (1.43), respectively. This results in

utijh)

E^l^ (-l)^(m!)^ k=0

Imh^ ^j-k

^j-k-

(1.47)

Finally, the approximation of ii£ by a forward difference with time step r leads to an iterative scheme whose first step reads

nf := h+r(-l)"'(m!)N^2 A < f l - 1
[imh^Y fc=0

d'j-k ^ 7m/i^

Uj-k-

(1.48)

Since our filter pair has the perfect reconstruction property (1.31), we have with

S0{s) = sin (1.39) that Uj = fj. Thus, u): ^ can be rewritten as

Mo-l

Mi-1

-f = HE'*^^-'^+ E/^K-fc-

fe=0

A;=0

i+2r(:^)":L"!?% m\di-k

(1.49)

Comparing this equation with (1.39) we see that the signal obtained by wavelet shrinkage coincides with those of the first step of our iterative scheme if

<, ,'ymh"' \ f^^h"^ ^ „ ( - i r m !

(1.50)

16

Weickert, Steidl, Mrazek, Welk & Brox

This fundamental relation generalises (1.21). It gives the connection between the shinkage function Se of single scale, shift-invariant wavelet shrinkage with m vanishing moments and the "diffusivity" g of the diffusion-like PDE (1.44) of order 2m. For m = 1 it coincides with our result (1.21) for Haar wavelet shrinkage. For m = 2v/& obtain

1.6 Summary
The goal of this chapter was to give a survey on connections between two discontinuity-preserving paradigms for signal and image denoising: wavelet shrinkage and nonlinear diffusion filtering. Unlike most other researchers in this field we focused on discrete connections. It turned out that the wavelet and the diffusion community can indeed learn much from each other. Focusing on soft Haar wavelet shrinkage and space-discrete TV diffusion, we showed that diffusion filters can benefit from wavelet shrinkage: It was possible to derive wavelet-inspired schemes for TV diffusion that are explicit, absolutely stable, do not require regularisations in order to cope with singularities, and perform favourably. On the other hand, investigating fully discrete schemes for nonlinear diffusion filtering and its higher-order generalisations allowed us to find a general relation between its diffusivity and the shrinkage function of shift-invariant wavelet shrinkage on a single scale. This led to diffixsion-inspired shrinkage functions with competitive performance, to shrinkage rules with improved rotation invariance, and to coupling strategies for wavelet shrinkage of colour images. Hence, also wavelet methods can benefit from diffusion methods. These connections give rise to the question whether it is also possible to design hybrid methods that benefit from both worlds by attempting to combine the efficiency of wavelet strategies with the quality of diffusion methods. They can be either regarded as iterated shift-invariant wavelet shrinkage methods, or as multiscale diffusion filters. First experiments confirm that this is indeed an interesting class of methods [587]. Performing a theoretical analysis of the connections between single-step multiscale procedures and iterated single scale methods, however, still leads to a lot of challenging questions. They are a topic of our current research.
Acknowledgements
Our research described in this chapter has been partly funded by the projects We 2602/2-1, We 2602/2-2, and We 2602/1 -1 of the Deutsche Forschungsgemeinschaft (DFG). This is gratefully acknowledged.

Chapter!
Total Variation Image Restoration: Overview and Recent Developments
T. Chan, S. Esedoglu, F. Park and A. Yip
Abstract Since their introduction in a classic paper by Rudin, Osher and Fatemi [695], total variation minimizing models have become one of the most popular and successful methodology for image restoration. More recently, there has been a resurgence of interest and exciting nev^ developments, some extending the applicabilities to inpainting, blind deconvolution and vectorvalued images, while others offer improvements in better preservation of contrast, geometry and textures, in ameliorating the staircasing effect, and in exploiting the multiscale nature of the models. In addition, new computational methods have been proposed with improved computational speed and robustness. We shall review some of these recent developments.
2.1 Introduction
Variational models have been extremely successful in a wide variety of restoration problems, and remain one of the most active areas of research in mathematical image processing and computer vision. By now, their scope encompasses not only the fundamental problem of image denoising, but also other restoration tasks such as deblurring, blind deconvolution, and inpainting. Variational models exhibit the solution of these problems as minimizers of appropriately chosen functionals. The minimization technique of choice for such models routinely involves the solution of nonlinear partial differential equations (PDEs) derived as necessary optimality conditions.
Perhaps the most basic (fundamental) image restoration problem is denoising. It forms a significant preliminary step in many machine vision tasks, such as object detection and recognition. It is also one of the mathematically most intriguing problems in vision. A major concern in designing image denoising models is to

18

Chan, Esedoglu, Park & Yip

preserve important image features, such as those most easily detected by the human visual system, while removing noise. One such important image feature are the edges; these are places in an image where there is a sharp change in image properties, which happens for instance at object boundaries. A great deal of research has gone into designing models for removing noise while preserving edges; recently there has also been a lot of effort in preserving other fine scale image features, such as texture. All successful denoising models take advantage of the fact that there is an inherent regularity found in natural images; this is how they attempt to tell apart noise and actual image information. Variational and PDE based models make it particularly easy to impose geometric regularity on the solutions obtained as denoised images, such as smoothness of boundaries. This is one of the main reasons behind their success.
Total variation based image restoration models were first introduced by Rudin, Osher, and Fatemi (ROF) in their pioneering work [695] on edge preserving image denoising. It is one of the earliest and best known examples of PDE based edge preserving denoising. It was designed with the explicit goal of preserving sharp discontinuities (edges) in images while removing noise and other unwanted fine scale detail. Being convex, the ROF model is one of the simplest variational models having this most desirable property. The revolutionary aspect of this model is its regularization term that allows for discontinuities but at the same time disfavors oscillations. It was originally formulated in [695] for grayscale imagery in the following form:

inf

/ \Vu\.

(2.1)

Here, ft denotes the image domain (for instance, the computer screen), and is usually a rectangle. The function f{x) : ft —> R represents the given observed image, which is assumed to be corrupted by Gaussian noise of variance cr^. The constraint of the optimization forces the minimization to take place over images that are consistent with this known noise level. The objective functional itself is called the total variation (TV) of the function u{x); for smooth images it is equivalent to the L^ norm of the derivative, and hence is some measure of the amount of oscillation found in the function u{x). Optimization problem (2.1) is equivalent to the following unconstrained optimization, which was also first introduced in [695]:

inf j \Vu\+\l {u-ffdx.

(2.2)

Here, A > 0 is a Lagrange multiplier. The equivalence of problems (2.1) and (2.2) has been established in [162]. In the original ROF paper [695] there is an iterative numerical procedure given for choosing A so that the solution u{x) obtained solves (2.1).
We point out that total variation based energies appear, and have been previously studied in, many different areas of pure and applied mathematics. For instance, the notion of total variation of a function and functions of bounded

Total Variation Image Restoration

19

variation appear in the theory of minimal surfaces. In applied mathematics, total variation based models and analysis appear in more classical applications such as elasticity and fluid dynamics. Due to ROF, this notion has now become central also in image processing.
Over the years, the ROF model has been extended to many other image restoration tasks, and has been modified in a variety of ways to improve its performance. In this article, we will concentrate on some recent developments in total variation based image restoration research. Some of these developments have led to new algorithms, and others to new models and theory. While we try to be comprehensive, we are of course limited to those topics and works that are of interest to us, and that we are familiar with. In particular, we aim to provide highlights of a number of new ideas that include the use of different norms in measuring fidelity, applications to new image processing tasks such as inpainting, and so on. We also hope that this article can serve as a guide to recent literature on some of these developments.

2.2 Properties and Extensions
2.2.1 BV Space and Basic Properties
The space of functions with bounded variation (BV) is an ideal choice for minimizers to the ROF model since BV provides regularity of solutions but also allows sharp discontinuities (edges). Many other spaces like the Sobolev space W^'^ do not allow edges. Before defining the space BV, we formally state the definition of TV as:
^ | V / | - s u p | ^ / V .gdx I g G C,i(n,]R-),|g(x)| < IVx G l^j (2.3)
where / G L^ [Q) and H C M^ is a bounded open set. We can now define the space BV as {/ G L^(17) | / ^ | V / | < oo}. Thus, BV functions amount to L^ functions with bounded TV semi-norm. Moreover, through the TV semi-norm there is a natural link between BV and the ROF model.
Given the choice oiBV{^) as the appropriate space for minimizers of the ROF model (2.2), there are the basic properties of existence and uniqueness to settle. The ROF model in unconstrained form (2.2) is a strictly convex functional, hence, admits a unique minimum. Moreover, it is shown in [162] that the equality constraint J^{u — f^dx = o^ in the non-convex ROF model (2.1) is equivalent to the convex inequaUty constraint ^^{u — f)^dx < a^. Hence, the non-convex minimization in (2.1) is equivalent to a convex minimization problem which under some additional assumptions is further equivalent to the above unconstrained minimization (2.2).
For BV functions there is a useful coarea formulation linking the total variation to the level sets giving some insight into the behavior of the TV norm. Given a function / G BVi^L) and 7 G M, denote by {/ == 7} the set:

20

Chan, Esedoglu, Park & Yip

{x G R^ I / ( x ) = 7 } . Then, if/ is regular, the TV of/ can be given by:

/ | V / | = r [ dsdj.

(2.4)

Jn

J-ooJ{f='y}

Here, the term Jr. . ds represents the length of the set {/ — ^y}. The formula

states that the TV norm of / can be obtained by integrating along all contours of

{/ = 7} for all values of 7. Thus, one can view TV as controlling both the size

of the jumps in an image and the geometry of the level sets.

2.2.2 Multi-channel TV
Total variation based models can be extended to vector valued images in various ways.
An interesting generalization of TV denoising to vector valued images was proposed by Sapiro and Ringach [704]. The idea is to think of the image u : R^ —> W^ as a parametrized two dimensional surface in W^, and to use the difference between eigenvalues of the first fundamental form as a measure of edge strength. A variational model results from integrating the square root of the magnitude of this difference as the regularization term.
Blomgren and Chan [98] generalized total variation regularization to vectorial data as the Euclidean norm of the vector of (scalar) total variations of the components. This generalization has the benefit that vector valued images defined on the line whose components are monotone functions with identical boundary conditions all have the same energy, regardless of their smoothness. This implies good edge preserving properties.
Another interesting approach generalizing edge preserving variational denoising models to vector valued images is due to Kimmel, Malladi, and Sochen [473]. They regard the given image u{x) : R^ —> R ^ as a surface in R^"^^, and propose an area minimizing flow (which they call Beltrami flow) as a means of denoising it.

2.2.3 Scale
The constant A that appears in the ROF model plays the role of a "scale parameter". By tweaking A, a user can select the level of detail desired in the reconstructed image. In this sense, A in (2.2) is analogous to the time variable in scale space theories for nonlinear diffusion based denoising models. The geometric interpretation of the regularization term in (2.2) given by the co-area formula suggests that A determines which image features are kept based on, roughly speaking, their "perimeter to area" ratio.
The intuitive link between A and scale of image features can be exactly verified in the case of an image that consists of a white disk on a black background. Strong and Chan [770] determined the solution of the ROF functional for such a given image f{x). It turns out to be (1 — ^ ) / ( x ) for A > :^. In particular, there is

Total Variation Image Restoration

21

always a loss of contrast in the reconstruction, no matter how large the fidelity constant A is. And when A < ^, the solution is identically 0, meaning that the model prefers to remove disks of radius less than j . This simple but instructive example indicates how to relate the parameter A to the scale of objects we desire to preserve in reconstructions. Strong and Chan's observation has been generalized to other exact solutions of the ROF model in [69].
The parameter A can thus be used for performing multiscale decomposition of images: Image features at different scales are separated by minimizing the ROF energy using different values of A. Recent research along these lines is described in section 2.5.3.

2.3 Caveats
While using TV-norm as regularization can reduce oscillations and regularize the geometry of level sets without penaHzing discontinuities, it possesses some properties which may be undesirable under some circumstances.
Loss of contrast. The total variation of a function, defined on a bounded domain, is decreased if we re-scale it around its mean value in such a way that the difference between the maximum and minimum value (contrast) is reduced. In [770, 567], the authors showed that for any non-trivial regularization parameter, the solution to the ROF model has a contrast loss. The example of a white disk with radius R over a black background discussed in 2.2.2 is a simple illustration. In this case, the contrast loss is inversely proportional to f{x)/r before the disk merges with the background. In general, reduction of the contrast of a feature by h > 0 would induce a decrease in the regularization term of the ROF model by 0{h) and an increase in the fidelity term by 0(/i^) only. Such scalings of the regularization and fidelity terms favors the reduction of the contrast.
Loss of geometry. The co-area formula (2.4) reveals that, in addition to loss of contrast, the TV of a function may be decreased by reducing the length of each level set. In some cases, such a property of the TV-norm may lead to distortion of the geometry of level sets when applying the ROF model. In [770], Strong and Chan show that, for circular image features, their shape is preserved at least for a small change in the regularization parameter and their location is also preserved even they are corrupted by noise of moderate level. In [69], Bellettini et al. extend Strong and Chan's results and show that the set of all bounded connected shapes C that are shape-invariant in the solution of the ROF model is precisely given by

C CR^ :C convex, a C e C^'^ and ess sup K,dc{p) < \dC\/\C\ \ .

p€dC

J

Here, \dC\ is the perimeter of C, \C\ is the area of C and Kdc{p) is the curvature of dC at p. The downside of the above characterization is that the ROF model distorts the geometry of shapes that do not belong to the shape-invariant set. For instance, it has been shown in [567], if the input image is a rectangle R over a

22

Chan, Esedoglu, Park & Yip

background with a different intensity, then cutting a comer (an isosceles triangle) with height h of the rectangle would induce a reduction in the TV-norm by 0{h) and an increment of the fitting term by 0 ( ^ ^ ) , thus favoring cutting the comers.
Staircasing. This refers to the phenomenon that the denoised image may look blocky (piecewise constant). In the 1-D discrete case, there is a simple explanation to this — the preservation of monotonicity of neighboring values. Such a property requires that, for each i, if the input / = {/^} satisfies fi < /i+i (resp. >), then the output must satisfy Ui < Ui^i (resp. >) for any A. In the case where / satisfies /i,j_i < /i^ > /i„+i < /io+2 for some ZQ, which often happens when the tme signal is monotonically increasing around io and is cormpted by noise but u satisfies Ujo-i < Ui^ = Ui^j^y < ^1^+2, then, visually, u looks like a staircase at zo but a monotonically increasing signal is more desirable. In the 2-D case, the monotonicity preserving property is no longer tme in general, for instance, near comers of image features. However, away from the comers where the curvature of the level sets is high, staircase is often observed.
Loss of Texture. Although highly effective for denoising, the TV norm cannot preserve delicate small scale features like texture. This can be accounted for from a combination of the above mentioned geometry and contrast loss caveats of the ROF model which have the tendency to affect small scale features most severely.

2.4 Variants
Total variation based image reconstmction models have been extended in a variety of ways. Many of these are modifications of the original ROF functional (2.2), addressing the above mentioned caveats.
2.4.1 Iterated Refinement
A very interesting and innovative new perspective on the standard ROF model has been recently proposed by Osher et al. [615]. The new framework involved can be generalized to many convex reconstmction models (inverse problems) beyond TV based denoising. When applied to the ROF model in particular, this new approach fixes a number of its caveats, such as loss of contrast, and promises even further improvements in other significant aspects of reconstruction, such as preservation of textures.
The key idea is to compensate for the loss of signal in reconstmcted images by minimizing the ROF model repeatedly, each time adding back the signal removed in the previous iteration. Thus, starting with a given fo{x) := f{x), repeat for i = l,2,3,...:
1. Set Uj{x) = argmin-n of (2.2) using fj{x) as the given image.
2. Set/,+i(x) = fj{x) + {f-uj{x)).

Total Variation Image Restoration

23

When applied to the characteristic function of a disk, this algorithm recovers it perfectly after a finite number of iterations without loss of contrast.
The algorithm can be generalized to inverse problems of the form inf^^ J{u) + H{u, / ) . Here, J is a convex regularization term, and H{u, f) a fidelity term that is required to be convex in u for every / . In this setting, the iterative procedure above becomes: Start with UQ = 0, repeat for j = 1 , 2 , 3 , . . .
Uj^i = argmiii H{w,f) + J{w) — J{uj) — {DuJ{uj),w — Uj). (2.5)
Here, DuJ{uj) denotes the derivative of the functional J at the j-th iterate Uj, and (•, •) represents the duality pairing. If J is non-differentiable (as in the ROF model), then DuJ{uj) needs to be understood as an element of the subgradient dJ{uj) of J at Uj. It is clear from formula (2.5) that the algorithm involves removing from the regularization term J{u) its linearization at the current iterate
Uj.
Formula (2.5) suggests the following definition: For p e dJ{v), let
DP{u, v) := J{u) - J{y) - (p, u - v)
be the generalized Bregman distance associated with the functional J . It defines a notion of distance between two functions u and v because it satisfies the conditions DP{u^ v) > 0 for all u, v, and D^[u, u) = 0. However, it is not a metric as it needs not be symmetric or satisfy a triangle inequality.
A number of important general theorems have been established in [615], including:
• As long as the distance of the reconstructed image Uj to the given noisy f{x) remains greater than a (the noise variance), the iteration decreases the Bregman distance of the iterates Uj to the true (i.e. noise-free) image.
• H{ujjf) decreases monotonically and tends to 0 as j —> oo.
In [615], further results can be found about the convergence rate of the iterates Uj to the given image / under certain regularity assumptions on / .

2.4.2 L^ Fitting

A simple way to modify the ROF model in order to compensate for the loss of contrast is to replace the squared L^ norm in the fidelity term in (2.2) by the L^ norm instead. The resulting energy is

f\Vu\+x[\

f\ dx.

(2.6)

Discrete versions of this model were studied for one dimensional signals by Alliney [14], and in higher dimensions by Nikolova [602]. In particular, it has been shown to be more effective that the standard ROF model in the presence of certain types of noise, such as salt and pepper. Recently, it has been studied in the continuous setting by Chan and Esedoglu [165].

24

Chan, Esedoglu, Park & Yip

Although the modification involved in (2.6) seems minor, it has certain desirable consequences. First and foremost, the scaling between the two terms of (2.6) is different from the one in the original ROF model (2.2), and leads to contrast invariance: lfu{x) is the solution of (2.6) with f{x) as the given image, then cu{x) is the solution of (2.6) with cf{x) as the given image. This property does not hold for (2.2). A related consequence is: If the given image f{x) is the characteristic function of a set ft with smooth boundary, then the image is perfectly recovered by model (2.6) for large enough choices of the parameter A. This is in contrast to the behavior of the ROF model, which always prefers to remove some of the original signal from the reconstructed one, and preserves a very small class of shapes. This statement can be generalized beyond original images given by characteristic functions of sets to show that a wide class of regular images are left unmodified by model (2.6) for large enough choices of the parameter A.
In addition to having better contrast preservation properties, model (2.6) also turns out to be useful for the denoising of shapes. A natural variational model for denoising a shape S, which we model as a subset of W^, is the following: minscR^ Per(S) + X\S A I]|, where the first term in the energy represents the perimeter of the set E, and the second represents the volume of the symmetric difference of the sets S and S weighted by the scale parameter A > 0. This model is exactly the one we would get if the minimization in the standard ROF model (2.2) is restricted to functions of the form u{x) = IY:{X) and f{x) = Is'(x). Unlike the standard ROF problem, however, this minimization is non-convex. In particular, standard approaches for solving it run the risk of getting stuck in local minima. The total variation model with L^ fidelity term (2.6) turns out to be a convex formulation of the shape denoising problem given above. Indeed, the following statement has been proved in [165]: Let u{x) be a minimizer of (2.6) for f{x) = ls{x). Then, for a.e. pi, e [0,1], the set E(//) = {j; G R ^ : u{x) > /i} is a minimizer of the shape denoising problem. Thus, in order to solve the nonconvex shape denoising problem, it suffices to solve instead the convex problem (2.6) and then take (essentially) any level set of that solution.

2,4.3 Anisotropic TV
In [299], Esedoglu and Osher introduced and studied anisotropic versions of the ROF model (2.2). The motivation is to privilege certain edge directions so that they are preferred in reconstructions. This can be useful in applications in which there may be prior geometric information available about the shapes expected in the recovered image. In particular, it can be used to restore characteristic functions of convex regions having desired shapes.
The idea proposed in [299] is to replace the total variation penalty term in (2.2) with the following more general term:

/ (j){Vu) := sup

/ u{x)dvvg{x) dx

Total Variation Image Restoration

25

where the function 0 : M^ —> R is a convex, positively one-homogeneous function that is 0 at the origin, and the set W^ is defined as follows:

W^:={yeW:X'y<

(j){x) \/x G R''} .

For example, if (/)(a;) — \x\, then the set Wff, turns out to be simply the unit ball {y e R^ : \y\ < 1}, and the definition of/^ (l){Vu) given above reduces to the standard definition of total variation. Another simple example in two dimensions \S(j){x,y) = \x\ 4- |y|, in which case the set W^ is just the closed unit square.
The set VK^ defined above is the Wulffshape associated with the function (j). It determines the shapes that are compatible with the anisotropy 0. For example, it is proved in [299] that i f / ( x ) is the characteristic function of (a scaled or translated version of) the Wulff shape W^, then the solution ti is a constant multiple of f{x). This result generalizes that of Strong and Chan [770] and Meyer in [567] that concern the case of a disk for the standard ROF model.
If W(f, is a convex polygon in two dimensions, then its sides act as preferred edge directions for the reconstructions obtained by the anisotropic ROF model. Indeed, it is proved in [299] that \iu{x) = I s ( ^ ) is a solution to the anisotropic model, and if S is known to be a set with piecewise smooth boundary dH, then dT, should include a line segment parallel to one of the sides of W^p wherever its tangent becomes parallel to one of those sides. On the other hand, one can show that dT, can include comers that are different than the ones in dW^.
In addition to being of interest for applications, the results of [299] are also of theoretical interest. Indeed, these anisotropic variants of total variation constitute an infinitude of equivalent regularizations (in the sense that the semi-norms they define are equivalent), yet the properties of their minimizers have been shown to be extremely different. That suggests that in general one should not expect an image restoration model to perform quite as well as the original ROF model just because its regularization term is equivalent to total variation.

2.4.4 H^'^ Regularization andInf Convolution
As discussed in Section 2.3, staircasing is one of the potential caveats to watch for when using total variation based regularization. It occurs even more severely in reconstructions by functionals that have a non-convex dependence on image gradients; one famous example is the Perona-Malik scheme, which can be thought of as gradient descent for such an energy functional whose dependence on image gradients grows sublinearly at infinity. The TV model is borderline convex: its dependence on image gradients is linear at infinity. This feature, which is responsible for its abihty to reconstruct images with discontinuities, is also responsible for the staircasing effect.
A natural approach to overcoming the staircasing effect is to make the reconstruction model more convex in regions of moderate gradient (away from the edges). A functional designed to accomplish this was proposed by Blomgren,

26

Chan, Esedoglu, Park & Yip

Mulet, Chan, and Wong [99]. It has the form

/ I Vi^l^('^^l) dx-i-X f {u- ff dx.

(2.7)

Here, the function P ( 0 • ^ ^ —^ [0? 2] is to be chosen so that it monotonically decreases from 2 to 0. A simple example is P{^) — T^-
The idea behind (2.7) is that the model automatically adapts the gradient exponent to fit the data, so that near edges it behaves exactly like the ROF model, and away from the edges it may behave more like the Dirichlet energy. This leads to much smoother reconstructions in regions of moderate gradient and thus prevents staircasing. On the other hand, unlike the ROF model, (2.7) is non-convex and difficult to analyze.
Another approach to preventing staircasing is to introduce higher order derivatives into the energy; the cost of moderately high but constant gradient regions is zero for such terms. On the other hand, a functional that depends on higher order derivatives would not maintain edges in its reconstructions. It is therefore necessary to once again allow the model to decide for itself where to use the total variation norm and where to use higher order derivative norms. One of the earliest proposals of this kind was made by Chambolle and Lions in [162], where they introduced the notion of inf convolution between two convex functionals. In this approach, an image u is decomposed into two parts: u = ui-{-U2. The ui component is measured using the total variation norm, while the second component U2 is measured using a higher order norm. The precise decomposition ofu into these two components is part of the minimization problem. More precisely, one solves the following variational problem that now involves two unknowns:

inf /
Ui,U2

\Vui\-ha\D^U2\-\-X{ui+U2-f)^dx.

Minimizing this energy requires the discontinuous component of the image to be allocated to the ui component, while regions that are well approximated by moderate but nearly constant slopes get allocated to the U2 component at very little cost. This prevents staircasing to a remarkable degree in the one dimensional examples presented in [162]. Another method that utilizes total variation and higher order derivatives to suppress staircasing is by Chan, Marquina, and Mulet in [168].
Despite the important contributions listed above, staircasing remains one of the challenges of total variation based image reconstructions.

2.5 Further Applications to Image Reconstruction
2.5.7 Deconvolution
The TV norm can also be used to regularize image deblurring problems. The forward degradation model for a blurred and noisy image can be realized as: / = k ^ u -{- rj, where / is the observed (degraded) image, k a given point spread

Total Variation Image Restoration

27

function (PSF), u the clean image, rj an additive noise (often Gaussian), and * denoting the convolution operator.
The task of restoring an image u under the above degradation is known as deconvolution if the PSF k is known or blind deconvolution if there is little or no known a priori information on the PSF. If we replace the u in the unconstrained ROF model (2.2) with the convolution k * u, then we arrive at the TV deconvolution model:

mm\\k^u-f\\l^X^\\u\\Tv-
u£BV

(2.8)

Here, as in the ROF model (2.2), the regularization parameter X^ is related to the

statistical signal to noise ratio (SNR).

Extending the work by You and Kaveh [911], Chan and Wong introduce in

[176] the TV blind deconvolution model:

min \\k^uu,kEBV

fWl + A^^II^IIITV + Afc||A;||Tv.

(2.9)

where the additional parameter Afc controls the spread of k. Moreover, solutions {u{Xk)} of (2.9) form a one parameter family corresponding to A^. The authors also propose an alternating minimization algorithm for minimizing the above energy (2.9) which we denote by F{u,k). Here, given u'^ one solves for k^~^^ := Bigi[nmkF{u^,k), then given k'^'^^, one solves for u^'^^ := argminxi F{u, k'^'^^) altematingly. Such an alternating procedure is shown to be convergent when the TV-norm is replaced by the H^-nonn.

A key advantage of using TV regularization for blind deconvolution is that the TV norm can recover sharp edges in the PSF (e.g. motion blur or out-of-focus blur) while not penalizing smooth transitions.

2.5.2 Inpainting
Image inpainting refers to the filling-in of missing or occluded regions in an image based on information available on the observed regions. A common principle for inpainting is to complete isophotes (level sets) in a natural way — such a philosophy is also true for professional artists to restore damaged ancient paintings. To this end, several successful inpainting models have been proposed such as Masnou and Morel [553] and Bertalmio et al. [79]. We refer the reader to [171] and the references therein for other more recent models. Among these models, Chan and Shen proposed in [171] a TV inpainting model which uses variational methods in inpainting. The basic ingredient is to solve the boundary value problem:

m i n / \Vu\ subject to U = UQ

'mQ.\D.

(2.10)

Here, D is the missing region to be inpainted, UQ is the observed image whose value in D is missing. Thus, the TV inpainting method simply fills-in the missing region such that the TV in O is minimized. The use of TV-norm is desir-

28

Chan, Esedoglu, Park & Yip

able because it has the effect of extending level sets into D without smearing discontinuities along the tangential direction of the boundary of D.
With a slight modification of (2.10), simultaneous inpainting (in D) and denoising (in Q.\D) may be done as follows:

min / \Vu\+\ / {^a-uofdx.

^ JQ,

Jn\D

(2.11)

Define a spatial varying parameter Ae(x) which is 0 in D and is A in H \ £). Then the Euler-Lagrange equation for (2.11) can be written as

which has the same form as that for the ROF model, except the regularization is switching between 0 and A in different regions. Thus, it is easy to modify an implementation of the ROF model to the TV inpainting model. Finally, we remark that some variants of (2.11) such as curvature-driven dififiision [172] and Euler's Elastica [167] have been proposed which complete isophotes in a smoother way.

2.5.3 Texture and Multiscale Decompositions
Another way of looking at denoising problems is by separating a given noisy image / into two components to form the decomposition: f = u-\- v, where u is the denoised image and v = f — uthe noise. In [567], Meyer adopts this view for the purpose of texture extraction where v captures not only noise but also texture. To do this, he proposed a new decomposition model:

inf|jE;(^)= f |Vi/|+A||i;||.,/ = ^-t-i;|

(2.12)

where the * norm is given by: ||«||. = inf ^{\\y/^^^T^U^\v = d^gi+dyg2}

(2.13)

and the v component lies in what is essentially the dual space of BV, the G space:

G={v\v = d,gi^ dyg2 , 91,92 G L^{R^)} .

(2.14)

Here, v is an oscillatory function representing texture and the * norm is designed to give small value for these functions. Thus, the main idea in (2.12) is to try to pull out texture by controlling ||^||*. Experiments in [843, 619] (discussed below) visually show that the model (2.12) extracts texture better than the standard ROF model.
In practice, the model (2.12) is difficult to implement due to the nature of the * norm. Vese and Osher [843] were the first to overcome this difficulty where they devise an L^ approximation to the norm || • ||*. In a later work [619], Osher et al. propose another L^ approximation based on the //~^ norm and introduce a resulting fourth order PDE. Both works numerically demonstrate the effectiveness

Total Variation Image Restoration

29

of the model (2.12) for texture extraction and also give some further applications to denoising and deblurring.
In a related work, Aujol et al. [36] propose a decomposition algorithm based on Meyer's work [567] where they further decompose an image a s / = u-\-v-}-w where u, v, and w are cartoon, texture, and noise respectively.
Given the scale properties of the ROF model seen in section 2.2.3, it is natural to consider a multiscale decomposition based on the ROF model. Multiscale decompositions are of particular interest since one may want to extract image features of many different scales (either coarse or fine). One such multiscale decomposition is Tadmor et al. [784] and proceeds in a hierarchical manner. After choosing an initial AQ = A to remove the smallest oscillation in a given image / , the regularization parameters {A^}, \j = 2^X induce a sequence of dyadic scales for jf = 1,...,/;:. If we denote by ux. the solution to the ROF model (2.2) for parameter \j, then / has the decomposition:
/ = UXo + tiAi + tiA2 + • • • + ^Afc + Vx^ .
with vxk denoting the k-th stage residual vx^ = f - {uxo + '^Ai + ux^ H H uxk). Furthermore, the authors show that Wvx^ ||* ^ 0 as A: ^ oo. Hence | | / J2i=o ^Ai II* —^ 0 as /u —> oo and the decomposition converges to / in the * norm. A related work based on merging dynamics of a monotonicity constrained TV model can be found in [169].

2.6 Numerical Methods
There have been numerous numerical algorithms proposed for minimizing the ROF objective. Most of them fall into the three main approaches, namely, direct optimization, solving the associated Euler-Lagrange equations and using the dual variable explicitly in the solution process to overcome some computational difficulties encountered in the primal problem. We will focus on the latter two approaches.

2.6.1 Artificial Time Marching and Fixed Point Iteration
In their original paper [695], Rudin et al. proposed the use of artificial time marching to solve the Euler-Lagrange equations which is equivalent to the steepest descent of the energy function. More precisely, consider the image as a function of space and time and seek the steady state of the equation

Sdt =V-f'T\\v^uV\p) 2A(.-/).

(2.15)

Here, \Vu\(3 := >/|Vii| + f3'^ is a regularized version of \Vu\ to reduce degeneracies in flat regions where | Vw| ~ 0. In numerical implementation, an expUcit time marching scheme with time step At and space step size Ax is used. Under

30

Chan, Esedoglu, Park & Yip

this method, the objective value of the ROF model is guaranteed to be decreasing and the solution will tend to the unique minimizer as time increases. However, the convergence is usually slow due to the Courant-Friedrichs-Lewy (CFL) condition, At < cAx-^|Vn| for some constant c > 0 (see [546]), imposed on the size of the time step, especially in flat regions where \Vu\ ^ 0. To relax the CFL condition, Marquina and Osher use, in [546], a "preconditioning" technique to cancel singularities due to the degenerate diffusion coefficient l/|Vw|:

(^)-'"-«

(2.16)

which can also be viewed as mean curvature motion with a forcing term — 2A(ii — / ) . Explicit schemes suggested in [546] for solving the above equation improve the CFL to At < cAx^ which is independent of \Vu\.
To completely get rid of CFL conditions, Vogel and Oman proposed in [849] a fixed point iteration scheme (FP) which solves the stationary Euler-Lagrange directly. The Euler-Lagrange equation is linearized by lagging the diffusion coefficient and thus the {i + l)-th iterate is obtained by solving the sparse linear equation:

While this method converges only linearly, empirically, only a few iterations are needed to achieve visual accuracy. In practice, one typically employs specifically designed fast solvers to solve (2.17) in each iteration.

2.6.2 Duality-based Methods
The methods described in Section 2.5.1 are based on solving the primal EulerLagrange equation which is degenerate in regions where Vu = 0. Although regularization by l/\Wu\f3 avoids the coefficient of the parabolic term becoming arbitrarily large, the use of a large enough /3 for effective regularization will reduce the ability of the ROF model to preserve edges.
Chan et al. in [166], Carter in [151] and Chambolle in [160] exploit the dual formulation of the ROF model By using the identity ||x|| = supn ||<i x • g for vectors in Euclidean spaces and treating g as the dual variable, one arrives at the dual formulation:

sup / / V • gdx - ; ^ / (V . g)^dx

g€Ci(n,s2)7n

^^ Jn

(2.18)

where B^ is the unit disk in M^. Once g is obtained, the primal variable can be recovered by u = / — A ~ ^ V - g . A promise of the dual formulation is that the objective function is differentiable in g, unlike the primal problem which is badly behaved when Vu = 0. However, the optimization problem becomes a constrained one which requires additional complexity to solve.

Total Variation Image Restoration

31

The approach used in [166] solves for u and g simultaneously. Its derivation starts by treating the term Vu/\Vu\ in the primal Euler-Lagrange equation as an independent variable g, leading to the system:
- V . g + A(tz - / ) = 0, g\Vu\(3 -Vu = 0.
The above system of nonlinear equations is solved by Newton's method and quadratic convergence rate is almost always achieved. In the Newton updates, one may combine the two equations to eliminate the need to update g, thus the cost per iteration is as cheap as the fixed point iteration (2.17). Empirically, this primal-dual method is much more robust than applying Newton's method directly to the primal problem in u only.
In [160], Chambolle devised an efficient algorithm solely based on the dual formulation (2.18). By carefully looking at the Euler-Lagrange equation for (2.18) and eliminating the associated Lagrange multipliers, one arrives at solving / / ( g ) - | / / ( g ) | = 0 where H{g) = - V ( / - A~^V • g) is the negative of the gradient of the primal variable u. The update formula for g used in [160] is a simple relaxation g'^"^^ = f-ft|///g^^)| ^^^^e r > 0 is chosen to be small enough so that the iteration converges.

Chapters
PDE-Based Image and Surface Inpainting
M. Bertalmio, V. Caselles, G. Haro, and G. Sapiro
Abstract Inpainting, the technique of modifying an image in an undetectable form, is as ancient as art itself The goals and applications of inpainting are numerous, from the restoration of damaged paintings, photographs and films, to the removal of selected undesirable objects. This chapter is intended to present an overview of PDE based image inpainting algorithms, with emphasis in models developed by the authors. These models are based on the propagation of information along the image isophotes and on the minimization of an energy functional which follows a relaxation of the Elastica model. This last variational formulation can be easily extended to 3D tofillholes in surfaces, a problem closely related to image inpainting. Basic PDE-based approaches to inpainting share the shortcoming that they cannot restore texture, so combinations of these algorithms with texture synthesis techniques are also discussed. Some results are shown for applications such as removal of text, restoration of scratched photographs, removal of selected objects and reconstruction of 3D surfaces with holes. Other recent approaches to the image inpainting problem are also briefly reviewed.
3.1 Introduction
The modification of images in a way that is non-detectable for an observer who does not know the original image is a practice as old as artistic creation itself. Medieval artwork started to be restored as early as the Renaissance, the motives being often as much to bring medieval pictures "up to date" as to fill in any gaps [298, 852]. This practice is called retouching or inpainting. The object of inpainting is to reconstitute the missing or damaged portions of the work, in order to make it more legible and to restore its unity [298].
The need to retouch the image in an unobtrusive way extended naturally from paintings to photography and film. The purposes remain the same: to revert dete-

34

Bertalmio, Caselles, Haro & Sapiro

rioration (e.g., cracks in photographs or scratches and dust spots in film), or to add or remove elements (e.g., removal of stamped date and red-eye from photographs, the infamous "airbrushing" of political enemies [475]).
Digital techniques are starting to be a widespread way of performing inpainting, ranging from attempts to fully automatic detection and removal of scratches in film [484, 485, 486], all the way to software tools that allow a sophisticated but mostly manual process.
This article is intended to be an overview of PDE based image inpainting algorithms, with emphasis in those models which were developed by the authors and that motivated a significant amount of effort in the area (some of the major contributions by other groups in image inpainting are briefly reviewed as well).
We should first note that classical image denoising algorithms do not apply to image inpainting. In common image enhancement applications, the pixels contain both information about the real data and the noise (e.g., image plus noise for additive noise), while in image inpainting, there is no significant information in the region to be inpainted. The information is mainly in the regions surrounding the areas to be inpainted. There is then a need to develop specific techniques to address these problems.
Mainly three groups of works can be found in the literature related to digital inpainting. The first one deals with the restoration of films, the second one is related to texture synthesis, and the third one is related to what we would call geometric inpainting.
Kokaram et al. [484,485, 486] use motion estimation and autoregressive models to interpolate losses in films from adjacent frames. The basic idea is to copy into the gap the right pixels from neighboring frames. The technique can not be applied to still images or to films where the regions to be inpainted span many frames.
There are many works on texture synthesis, of which the most notable are based on Markov Random Fields after the pioneering work of Efros and Leung [297]. These techniques synthesize texture which is both stationary and local [869]. In [297] a new texture is incrementally synthesized by considering similar neighborhoods in the sample texture. Igehy and Pereira [416] replace image regions with synthesized texture [392, 745] according to a given mask. Ashikhmin [32] adds the constraint that the synthesized texture match a sample image. This yields the effect of rendering a given image with the texture appearance of a training texture. Efros and Freeman [296] introduce a simple and effective texture synthesis technique that synthesizes a new texture by stitching together blocks of existing sample texture. The results depend on the size of a block which is a parameter tuned by the user that varies according to the texture properties. Hirani and Totsuka [400] combine frequency and spatial domain information in order to fill a given region with a user-selected texture. We will later show how texture synthesis can be combined with PDE-based inpainting techniques to obtain state-of-the-art algorithms.
Finally, let us mention the geometric approaches used for filling-in the missing information in a region of the image. A pioneering contribution in the recovery

PDE-Based Image and Surface Inpainting

35

of plane image geometry is due to D. Mumford, M. Nitzberg and T. Shiota [604]. They were not directly concerned with the problem of recovering the missing parts of the image, instead, they addressed the problem of segmenting the image into objects which should be ordered according to their depth in the scene. The segmentation functional should be able to find which are the occluding and the occluded objects while finding the occluded boundaries. For that they relied on a basic principle of Gestalt's psychology: our visual system is able to complete partially occluded boundaries and the completion tends to respect the principle of good continuation [453]. When an object occludes another the occluding and occluded boundaries form a particular configuration, called T-junction, which is the point where the visible part of the boundary of the occluded object terminates. Then our visual system smoothly continues the occluded boundary between Tjunctions. In [604], the authors proposed an energy functional to segment a scene which took into account the depth of the objects in the scene and the energy of the occluded boundaries between T-junctions. They assumed that the completion curves should be as short as possible and should respect the principle of good (smooth) continuation. Thus, to define the energy of the missing curve they had to give a mathematical formulation of the above principles. Given two T-junction points p and q and the tangents Tp and Tq to the respective terminating edges, they proposed as smooth continuation curve Euler's elastica, i.e., the curve minimizing the energy

f {a-{-pK^)ds

(3.1)

Jc

where the minimum is taken among all curves C joining p and q with tangents Tp

and Tq, respectively, K denotes the curvature of C, ds its arc length, and a, /? are

positive constants. Let us mention that Euler's elastica has been frequently used

in computer vision ([406, 511, 735,795,796, 821, 892, 893, 891]) and a beautiful

account on it can be found in [589].

Inspired by the elastica, Masnou and Morel [551, 553, 552] proposed a

variational formulation for the recovery of the missing parts of a grey level two-

dimensional image and they referred to this interpolation process as disocclusion,

since the missing parts can be considered as occlusions hiding the part of the

image we want to recover. Their algorithm performs filling-in by joining with

geodesic curves the points of the isophotes arriving at the boundary of the region

to be inpainted.

Mumford's work on the Elastica Model and Masnou and Morel's contribu-

tion inspired Bertalmio, Sapiro, Caselles and Ballester [79] to propose an edge

propagation PDE for the Image Inpainting formulation. Replicating basic art con-

servators techniques, a third order PDE propagates the level lines arriving at the

missing region, and the completion tends to respect the principle of good con-

tinuation. Bertalmio , Bertozzi and Sapiro [77] showed the connection of this

equation with Navier-Stokes equations, as well as a parallel among Image Pro-

cessing and Fluid Dynamics quantities. On the other hand, Ballester, Bertalmio,

Caselles, Sapiro and Verdera [46] introduce a relaxation of the Elastica functional

36

Bertalmio, Caselles, Haro & Sapiro

which then can be minimized with a system of coupled PDE's: this is the first variational approach to the inpainting problem that complies with thQ principle of good continuation and is topologically independent.
The elastica has inspired most variational approaches to geometric image inpainting [46, 48, 47, 167, 544] and we shall discuss in detail some of them in Section 3.3. In particular, the approach in [47, 840] can be used for inpainting 3D images and surface hole reconstruction. Some other PDE methods for surface hole reconstruction will be discussed in Section 3.4.
This article is organized as follows. Section 3.2 discusses inpainting by propagation of information: PDE methods that propagate image quantities and do not expUcitly minimize any functional. Section 3.3 discusses variational methods for inpainting: the inpainting problem is solved as the minimization of an energy functional. In Section 3.4 we show how can we use the Laplace and AMLE (Absolutely Minimizing Lipschitz Extension) interpolators in surface hole reconstruction. None of these purely-PDE-based methods can restore texture, so in Section 3.5 we discuss how to adapt those algorithms to deal with texture. Finally, in Section 3.6 we briefly mention some other recent works on the inpainting problem. We finish with Appendix 3.8 where we collect some notation and definitions used in the text.

3.2 Inpainting by Propagation of Information
3.2.1 Image Inpainting
In [79], Bertalmio, Sapiro, Caselles and Ballester propose to translate into mathematical form the most basic techniques used by art conservators and restorators to inpaint, introducing also the art term 'inpainting' to the Image Processing and Graphics community.
Conservators at the Minneapolis Institute of Arts were consulted for this work and made it clear that inpainting is a very subjective procedure, different for each work of art and for each professional. There is no such thing as "the" way to solve the problem, but the underlying methodology is as follows: (1.) The global picture determines how to fill in the gap, the purpose of inpainting being to restore the unity of the work; (2.) The structure of the area surrounding the gap Q, is continued into it, contour lines are drawn via the prolongation of those arriving at the gap boundary dVl; (3.) The different regions inside H, as defined by the contour lines, are filled with color, matching those of dVt\ and (4.). The small details are painted (e.g. little white spots on an otherwise uniformly blue sky): in other words, "texture" is added.
The algorithm in [79] simultaneously, and iteratively, performs the steps (2.) and (3.) above. The gap H shrinks progressively by prolonging inward, in a smooth way, the lines arriving at the gap boundary dVt. The image beyond dO. is not taken into account, and texture is not dealt with (yet) with this first technique.

PDE-Based Image and Surface Inpainting

37

The following exposition considers the grayscale case; for color images, the authors apply their method to each of the three channels separately, but using a color model like CIE - Lab instead of RGB, to avoid color artifacts.
The digital inpainting procedure will construct a family of images u{i,j, n) : [0, M] X [0, A^] X W -^ iR such that u{i, j , 0) = ^0(7:, j) and limn-^00 u{i, j , n) == UR{hJ)i where uo(i,j) is the image to inpaint and UR{i,j) is the output of the algorithm (inpainted image).
Any general algorithm of that form can be written as:

^"-"'(i, j ) - u^iij) + A t < ( ^ j ) , V(z, j ) G n

(3.2)

where the superindex n denotes the inpainting "time" n, {i,j) are the pixel coordinates, A^ is the rate of improvement and u^{i,j) stands for the update of the image u^(i,j). Note that the evolution equation runs only inside ft, the region to be inpainted.
To design the update u'i{i,j), the authors call L^{i,j) the information that
needs to be propagated into the gap, and N'^{i,j) the propagation direction:

u^(i,j)=VL»{i,j)-N"{i,j),

(3.3)

With equation (3.3), they estimate the information L^{i,j) of the image and
compute its change along the N'^ direction. Note that when the algorithm con-
verges, u^'^^{i,j) = u^{i,3) and from (3.2) and (3.3) we have that VL'^{i,j) •
N'^{i, j) = 0, meaning exactly that the information L has been propagated in the —>
direction N. Bearing in mind that the goal is to propagate contours and that the Laplacian has
been frequently used as an edge detector, the authors choose for L^{i, j) a monotone increasing function of the Laplacian, the most simple one being the Laplacian itself. Thus, the proposed choice is L'^{i,j) = Au^(z, j ) . Other edge detectors like Canny's edge detector which leads to the choice L^ = {V'^u'^^Vu'^), Vu'^) could be used.
For the field N, the natural choice is the isophotes directions. This is a bootstrapping problem: having the isophotes directions inside Q is equivalent to having the inpainted image itself, since we can easily recover the gray level image from its isophote direction field (see [460],[639]). They use then a time varying estimation of the isophotes direction field: N{i,j, n) = V-^u'^{i,j)
In terms of a continuous process, the inpainting procedure can be expressed as a third-order PDE:

du{x,y,t) _^Vf{^A^u^{fx^,y,^t).)^^^'V^^_uL{x,y,t))y{x,y) G n (3.4) dt
To ensure a correct evolution of the direction field, a diffusion process is interleaved with the image inpainting process described above. This diffusion cor-

38

Bertalmio, Caselles, Haro & Sapiro

Figure 3.1. Restoration of an old photograph.

PDE-Based Image and Surface Inpainting

39

XI y X I I , e l

Figure 3.2. Removal of superimposed text.

responds to the periodical curving of lines to avoid them from crossing each other, as art conservators do. The authors use anisotropic diffusion, [15, 642], in order to achieve this goal without losing sharpness in the reconstruction:

— {x,y,i) = K{x,y,t)\Vu(x,y,t)\y{x,y) G 17

(3.5)

where K is the Euclidean curvature of the isophotes ofu. For the numerical implementation, a forward-time upwind scheme is used for
(3.4) and a forward-time centered-space scheme for (3.5); see [618, 695] for details . To speed up the process, a non-linear scaHng is applied to ut in (3.4): Ut = sign(itt) \ut\^. With a time step Ait of 0.1, one step of anisotropic diffusion is run every fifteen steps of inpainting. Convergence is typically achieved after a few thousands iterations, depending on the size of U and the initial condition inside it. The process may be sped-up by the use of multi-resolution for wide gaps, and by pre-processing by running a few steps of the Heat Equation inside Vt to get a good initial condition:

•^(•'^,2/,0 = ^u[x,y,t)y{x,y) e ft

(3.6)

See examples in figures 3.1 and 3.2. In both cases, the algorithm is supplied only with the image to restore and a binary mask that specifies the region to restore. In figure 3.1, a deteriorated photograph is restored, the mask having been manually selected with a simple paintbrush-like program by a non-specialist. Observe that details in the nose and right eye of the middle girl could not be completely restored. This is in part due to the fact that the mask covers most of the relevant information, and there is not much to be done without the use of high level prior information (e.g., the fact that it is an eye). These minor errors can be corrected by the manual procedures mentioned in the introduction, and still the overall inpainting time would be reduced by orders of magnitude.
Figure 3.2 shows a color example: results are sharp and without color artifacts. This image is very ill-suited for texture synthesis algorithms, since the image gap n covers most of the image, which also has a very diverse background.
The technique presented above does not require any user intervention, once the region to be inpainted has been selected. The algorithm is able to simultaneously

40

Bertalmio, Caselles, Haro & Sapiro

fill regions surrounded by different backgrounds, without the user specifying "what to put where." No assumptions on the topology of the region to be inpainted, or on the simplicity of the image, are made. The algorithm is devised for inpainting in structured regions (e.g., regions crossing through boundaries), though it is not devised to reproduce textured areas.

3.2.2 Navier-Stokes Inpainting
In [77], the authors propose an approach that uses ideas from classical fluid dynamics to propagate isophote lines continuously from the exterior into the region to be inpainted. The main idea is to think of the image intensity as a 'stream function' for a two-dimensional incompressible flow. The Laplacian of the image intensity plays the role of the vorticity of the fluid; it is transported into the region to be inpainted by a vector field defined by the stream function. The resulting algorithm is designed to continue isophotes while matching gradient vectors at the boundary of the inpainting region. The method is directly based on the Navier-Stokes equations for fluid dynamics, which has the immediate advantage of well-developed theoretical and numerical results. Existence and stability of the solution to the proposed algorithm follow from the Navier-Stokes theory, and the implementation is based on numerical methods used by the fluid dynamics community.
In [77], the authors start by re-introducing the inpainting method of [79]:

ut = V^u • VAiA

(3.7)

and noting that its dynamics are those of a transport equation that convects the image intensity u along level curves of the smoothness, Au. This can be seen by noting that (3.7) is equivalent to Du/Dt = 0 where D/Dt is the material derivative d/dt -f t; • V for the velocity field v = V-^Au. In particular u is convected by the velocity field v which is in the direction of level curves of the smoothness Au.
Next, the authors introduce an analogy to transport of vorticity in incompressible fluids. Incompressible Newtonian fluids are governed by the Navier-Stokes equations, which couple the velocity vector field t; to a scalar pressure p [195]:

Vt-^V'Vv = -Vp-\-iyV^v, V-v = 0.

(3.8)

In two space dimensions, the divergence free velocity field v possesses a stream function ^ satisfying V"*-^ = v. In addition, in 2D the vorticity, LJ = V x v, satisfies a very simple advection diffusion equation, which can be computed by taking the curl of the first equation in (3.8) and using some basic facts about the geometry in 2D:

uJt-{-V'Vuj = lyV^uj.

(3.9)

PDE-Based Image and Surface Inpainting

41

Note here that in 2D the vorticity is a scalar quantity that is related to the stream function through the smoothness or Laplacian operator, A ^ = a;. In the absence of viscosity «/ = 0, we obtain the Euler equations for inviscid flow.
Both the inviscid and viscous problems, with appropriate boundary conditions, are globally well-posed in two space dimensions. Solutions exist for any smooth initial condition and they depend continuously on the initial and boundary data [500].
In terms of the stream function, equation (3.9) implies that steady state inviscid flows must satisfy

V-^^VA^=0

(3.10)

which says that the Laplacian of the stream function, and hence the vorticity, must have the same level curves as the stream function. The analogy to image inpainting in the previous section is now clear: the stream function for inviscid fluids in 2D satisfies the same equation as the steady state image intensity equation (3.7).
The authors then procceed to present a 'Navier-Stokes' based method for image inpainting. In this method the fluid dynamic quantities have the following parallel to quantities in the inpainting method:

Navier-Stokes
stream function ^ fluid velocity v = V-^^ vorticity a; = — A ^

Image inpainting
Image intensity u isophote direction V-^u smoothness w = Au

where they denote by w the smoothness Au of the image intensity. Instead of solving a transport equation for u as in (3.7), they solve a vorticity transport equation forw:

dw/dt -]-V'S/w = uV ' {g{\Vw\)\/w),

(3.11)

where the function g allows for anisotropic diffusion of the smoothness w. The image intensity u which defines the velocity field v = V-^n in (3.11) is
recovered by solving simultaneously the Poisson problem

Au = w, u\dQ=uo>

(3-12)

For g — 1, the direct numerical solution of of (3.11-3.12) is a classical way to solve both the dynamic fluid equations and to evolve the dynamics towards a steady state solution [644].
When using any PDE-based method to do inpainting, the issue of boundary conditions becomes very important. In order to produce a result which, to the eye, does not distiguish where the inpainting has taken place, we must at the very least propagate both the image intensity and direction of the isophote lines continuously into the inpainting region.
This means that any PDE-based method involving the image intensity u must enforce Dirichlet (fixed a) boundary conditions as well as a condition on the di-

42

Bertalmio, Caselles, Haro & Sapiro

rection of Vu on the boundary. Immediately we see that this poses a problem for lower-order PDE-based methods. Indeed, any first or second order PDE (including anisotropic diffusion) for the scalar u could typically only enforce one of these boundary conditions, the result being an inpainting with discontinuities in the slope of the isophote lines, or a method with a jump in u itself on the boundary [172]. From a mathematical point of view, to fix this, one can either go to a higher order equation for u, as in [79], that requires more boundary conditions, or consider a vector evolution for Vu, which is the idea of the Navier-Stokes method.
The Navier-Stokes analogy guarantees, in a very natural way, continuiuty of the image intensity function u and its isophote directions across the boundary of the inpainting region. First, consider a solution of the Navier-Stokes equation (3.8) in primitive variables form satisfying the classical no-slip condition ?; = 0 on the boundary dCt. This condition guarantees two features: (a) that the stream function ^ must be constant on the boundary, since the boundary is trivially a streamline of the flow; (b) that the direction of the fluid velocity v is always tangent to the boundary.
A general form of the no-slip boundary condition, for which well-posedness is known, is to prescribe the velocity vector t* == VQ on the boundary. This would be the natural choice for a moving boundary. Specifying the velocity on the boundary is equivalent to specifying both the normal and tangential derivatives of the stream function ^ on the boundary, since v = V ^ ^ . However, specifying the tangential derivative of ^ determines ^ on the boundary up to a constant of integration, by simply integrating around the boundary with respect to its arc length. Similarly this information determines the direction of flow on the boundary. The result is that if we solve the Navier-Stokes equations with v fixed on the boundary, we obtain a solution with a stream function ^ and velocity field v both of which are continuous up to the boundary. For the Navier-Stokes inpainting method, we inherit the continuity across the boundary. For example, suppose we fix V^u on the boundary. Then solving the Navier-Stokes inpainting equation with these boundary conditions will not only result in continuous isophotes, but also will produce an image intensity function that is continuous across dO..
As for well-posedness and uniqueness of solutions, the authors note that without the presence of viscosity in the method there is not a unique steady-state solution. They expect that Navier-Stokes based inpainting may inherit some of the stability and uniqueness issues known for incompressible fluids, although the effect of anisotropic diffusion is not clear.

3.3 Variational Models for Filling-In
This section is a review of variational models for filling-in. We start with the elastica-based disocclusion model introduced by Masnou and Morel [551, 553]. Then we present the filling-in approach by joint interpolation of vector fields and

PDE-Based Image and Surface Inpainting

43

gray levels proposed by Ballester et al. in [46, 48, 47]. The connections of this model with T. Chan and J. Shen approach [167] are then considered.

3.3.1 Elastica-based Reconstruction of Level Lines

We review the main assumptions of Masnou's approach to disocclusion [551, 553]. An image is usually modeled as a function defined in a bounded domain D C IZ^ (typically A/" = 2 for usual snapshots. A/" == 3 for medical images or movies) with values in 7& (/c = 1 for grey level images, or A: — 3 for color images). For simpHcity, we shall consider only the case of grey level images. Any real image is determined in a unique way by its upper (or lower) level sets Xxu := {x e D : u{x) > A} (X'^u := {x e D : u{x) < A}). Indeed we have the reconstruction formula

u{x) = sup{A e R:x e Xxu}.

(3.13)

The basic postulate of Mathematical Morphology prescribes that the geometric information of the image u is contained in the family of its level sets [371, 723], or in a more local formulation, in the family of connected components of the level sets ofu [154, 723, 726]. We shall refer to the family of connected components of the upper level sets of u as the topographic map of u.
In the case that it is a function of bounded variation in D C 7^^, i.e., u e BV{D) (see Appendix and [19, 301, 926]), its topographic map has a description in terms of Jordan curves [18]. With an adequate definition of connected components, the essential boundary of a connected component of a rectifiable subset of 7^^ consists, modulo an H^ null set, of an exterior Jordan curve and an at most countable family of interior Jordan curves which may touch in a set of 7^^-null Hausdorff measure [18]. Since almost all level sets Xxu of a. function u of bounded variation are rectifiable sets, its essential boundary, d*Xxu, consists of a family of Jordan curves called the level lines oiu. Thus, the topographic map of li can be described in terms of Jordan curves. In this case, the monotone family of upper level sets Xxu suffices to have the reconstruction formula (3.13) which holds almost everywhere [371].
Let D be a square in R? and O be an open bounded subset of D with Lipschitz continuous boundary. Suppose that we are given an image UQ : D\Vt —> [a, 6], 0 < a < 6. Using the information of ?xo on Z ) \ n we want to reconstruct the image UQ inside fi. We shall call Vt the hole or gap. We shall assume that the function 1^0 is a function of bounded variation in £> \ H. Then the topographic structure of the image UQ outside (l is given by a family of Jordan curves. Generically, by slightly increasing the hole, we may assume that, for almost all levels A, the level lines of XXUQ transversally intersect the boundary of the hole in a finite number of points [551]. Let us call A C 7?, the family of such levels. As formulated by Masnou [551, 553, 552], the djsocclusion problem consists in reconstructing the topographic map of lio inside 17. Given A G A and two points p,q G Xxu^f} d(l

44

Bertalmio, Caselles, Haro & Sapiro

whose tangent vector at the level line XXUQ is Tp and Tq, respectively, the optimal completion curve proposed in [551, 553] is a curve F contained in H minimizing the criterion

J{a + P\K\ndn' + (rp,rr(p)) + ( r „ r r ( ^ ) )

(3.14)

where K, denotes the curvature of F, rr(p) and rr{q)) denote the tangents to F at the points p and q, respectively, and (rp,rr(p)), (Tg,rr(g)) denote the angle formed by the vectors Tp and rr{p), and, respectively, for q. Here a, p are positive constants, and p > I. The optimal disocclusion is obtained by minimizing the energy functional

/ " y2([i^ + Mndn'^{TpMp))^{rq,Tr{q)))dX

(3.15)

where F \ denotes the family of completion curves associated to the level set XXUQ. AS we noted above, the family FA is generically finite, thus the sum in (3.15) is generically finite. In [551, 553] the authors proved that for each p > I there is an optimal disocclusion in O and proposed an algorithm based on dynamic programming to find optimal pairings between compatible points in dXxuo n dfl forp = 1, curves which are straight lines, thus finding in this case the minimum of (3.15) [551, 552]. In [20] the authors proposed a slight variation of the disocclusion energy fiinctional (3.15). First, they observed that by computing the criterion / p ( a -f P\K,\P)d7i^ not only on the completion curve but also in a small piece of the associated level line outside 0 , the criterion (3.15) can be written as

/ y " if {oc^-p\K\^)dn^)d\

7-00 r t ^ . V r

^

(3.16)

where now the curves in Fx are union of a completion curve and a piece of level line of lio in n \ n for a domain H D O. This requires that the level lines of UQ are essentially in ly^'^ in H \ il. Then, at least for C^ functions u, (3.16) can be written as

p

/ \Vu\[a^f3 div

)dx

JQ

|V«|

(3.17)

with the convention that the integrand is 0 when \Vu\ = 0. In [20], the authors considered this functional when the image domain D and the hole n are subsets in 7^^ whit N >2 and they studied the relaxed functional, proving that it coincides with

/ / {a + P\Hiu>t]\ndn''-Ut
JR Jd[u>t]

(3.18)

for functions u G C'^{fl), N > 2, p > N - 1, and ^[u>t] denotes the mean curvature of fn > t\.

PDE-Based Image and Surface Inpainting

45

Figure 3.3. The hole and the band
3.3.2 Joint Interpolation of Vector Fields and Gray Levels
In [46, 48, 47], Ballester et al. proposed to fill-in the hole H using both the gray level and the vector field of tangents (or normals) to the level lines of the image outside the hole. Let D be_a hyperrectangle in IZ^, N > 2, which represents the image domain, and let H J l be two open bounded domains in IZ^ with Lipschitz
boundary. Suppose that Q. m ft <& D (for simplicity, we assume that ft does not touch the boundary of the image domain D). Suppose that the image UQ is given
in £> \ n . Let B := ft\ft. The set B will be called the band around fl (see Figure 3.3).
To fill-in the hole ft we shall use the information ofuo contained in B, mainly the gray level and the vector field of normals (or tangents) to^the level lines of-UQ in 5 . We attempt to continue the level sets ofuo in B inside ft taking into account the principle of good continuation. Let ^o be the vector field of directions of the gradient of UQ on D \ Q, i.e., ^o is a vector field with values in 7^^ satisfying 9o{x) • Duo{x) = \Duo{x)\ and |^o(^)| < 1. We shall assume that ^o(^) has a trace on dft.
We pose the image disocclusion problem in the following form: Can we extend (in a reasonable way) the pair of functions {UQ, OQ) from the band O \ (7 to a pair of functions (u, 6) defined inside ft ? Of course, we will have to precise what we mean by a reasonable way.
The data UQ is given on the band B and we should constrain the solution u to be near the data on B, The vector field 0 should satisfy 6 • v^ z=z Q^ . if^^\0\ < l on ft and should be related to u by the constraint 0 • Du = \Du\, i.e., we should impose that 9 is related to the vector field of directions of the gradient ofu. The condition \0{x)\ < 1 should be interpreted as a relaxation of this. Indeed, it may happen that 0{x) =0 (flat regions) and then we cannot normalize the vector field to a unit vector (the ideal case would be that 6 = m^\^ ^ being a smooth function with Du{x) ^ 0 for all x e ft). Finally, we should impose that the vector field 9o in D \ ft is smoothly continued by 9 inside ft. Note that if 9 represents the directions of the normals to the level lines ofu, i.e., of the hypersurfaces u{x) = X,Xe1Z, then div(^) represents its mean curvature. We shall impose the smooth continuation of the levels lines of uo inside ft by requiring that div (9) e L^ift), p> 1.

46

Bertalmio, Caselles, Haro & Sapiro

Interpreting the elastica functional in this framework, we propose to minimize the functional

Minimize / \dw{0)\P{-f -\- p\VK ^ u\)dx
JQ
\e\ < 1, \Du\-o Du^oinn
\u\ <M

(^-^^^

where p > 1,7 > 0, /? > 0, po = Oo'i/^,K denotes a regularizing kernel of class C^ such that K{x) > 0 a.e., M = sup^,^^ |uo(x)|, u^ and denotes the outer unit normal to H. The convolution of Du with the kernel A' in (3.19) is necessary to be able to prove the existence of a minimum of (3.19).
The functional can be interpreted as a formulation of the principle of good continuation and amodal completion as formulated in the Gestalt's theory of vision.
Comments on model (3.19). A) Could we fill-in the hole without the band? To discuss this suppose that we are given the image of Figure 3.4.a, which is a gray band on a black background partially occluded by a square ft. We suppose that the sides of the square hole 0 are orthogonal to the level lines of the original injage. In these conditions, the normal component of the vector field ^0 outside H is null at dCl. Thus if the boundary data is just ^0 * ^ ^ I ^ Q , we would have that <^o • ^ ^ I ^ Q = 0. In particular, the vector field ^ = 0 satisfies this condition. If we are not able to propagate 9 inside Q. this may become an unpleasant situation, since this would mean that we do no propagate the values ofu at the boundary. If we write the fiinctional (3.23) with ^ = 0, a = 1, it turns out to be the Total Variation [695]. The decision of extending the gray band or filling-in the hole with the black gray level would be taken as a function of the perimeter of the discontinuities of the function in the hole. Then the result of interpolating Figure 3.4.a, using Total Variation would be that of Figure 3.4.b, and not the one in Figure 3.4.c, because the interpolating lines in Figure 3.4.b, are shorter than the ones in Figure 3.4.c. To overcome this situation we introduce the band around the hole. The introduction of the band permits us to effectively incorporate in the functional the information given by the data UQ and the vector field 0 outside O. In Figure 3.4.b, we display the result of the interpolation with ^ = 0 on H. In Figure 3.4.c, we display the result of the interpolation using (3.23), which takes into account the band B and computes the vector field OinQ.
In practice, we suppose that only a narrow band around the hole influences what happens inside the hole, even if, in principle, it could be extended to all the known part of the image.

PDE-Based Image and Surface Inpainting

47

Figure 3.4. a) Left: a strip with a hole, b) Middle: image disocclusion obtained using Total Variation, c) Right: Image disocclusion obtained using functional (3.23).

B) If A^ = 2 and u is the characteristic function of the region enclosed by a smooth (C^) curve C then the terms

p f \dW{e)\P\Du\-{-a f \Du\

Jn

Jn

(3.20)

can be written as JQ{OC H- P\K\P)ds, where K is the Euclidean curvature (of the level-sets). If p = 2, this coincides with Euler's elastica (3.1). Euler's elastica (3.1) was proposed in [604] as a technique for removing occlusions with the goal of image segmentation, since this criterion yields smooth, short, and not too curvy curves. In terms of characteristic functions, Euler's elastica can be written as

/|V.|(a + /.|...(i|^)

(3.21)

In [70], it was shown that the elastica functional is not lower semicontinuous. As shown in [20], the functional proposed by Masnou and Morel [551, 552, 553] can be interpreted as a relaxation of it, since it integrates functionals like the elastica along the level lines of the function u. Our functional can be also considered as a relaxed formulation of the energy of the elastica. For that, we introduced 0 as a independent variable, and we tried to couple it to u by imposing that 0 • Du = \Du\. Finally, let us say that to be able to prove the existence of a minimum for (3.23) we have convolved the Du term of (3.20). This permits to avoid some of the mathematical difficulties involved in the study of (3.21).
C) Both coefficients 7 and 0 are required to be > 0. The positivity of 7 gives us an LP bound on div(^) which implies the regularity of the level lines ofu ([554,47]). If we do not take P > 0,0 = 0 a.e. on B (or on ft) in the image of Figure 3.4.a (since ^ = 0 except on some curves) and the term J^ \diY{9)\Pdx would produce a null value since div(^) = 0. If/^ > 0 we take into account the contribution of a power of the curvature on the level line corresponding to the boundary of the object.
D) In practice, functional (3.23) is used to interpolate shapes, i.e., to interpolate level sets. The image is decomposed into upper level sets [UQ > A], which are interpolated using (3.23) to produce the level sets Xxu of a function u, which is reconstructed inside Q. by using the reconstruction formula (3.13). To guarantee

48

Bertalmio, Caselles, Haro & Sapiro

I I I Ii

Figure 3.5. a) Left: a double cross with holes, b) Right: reconstructed image using functional (3.23). Observe that due to our choice of upper level sets to decompose and reconstruct the image, the white bar goes above the black ones.
that the reconstructed level sets correspond to the level sets of a function u, they should satisfy that Xx^iu C Xxu. In practice, we force our solution to satisfy this property.
Functional (3.23) could be used to interpolate functions. But, discontinuities of the image have a contribution to the energy which is proportional to the jump. This gives different weights to discontinuities of different sizes and, as a consequence, they are not treated in the same manner. When taking level sets, we treat all shapes equally, and the parameters of the functional weight geometric quantities (like length, total curvature) and decide which interpolation is taken as a function of them. This approach is less diffusive than directly interpolating the gray levels. A numerical implementation of (3.19) is possible using the scheme in [46].
E) The choice of decomposing the image UQ into upper level sets, interpolating them and reconstructing the function u, introduces a lack of symmetry (of upper level sets versus lower level sets). This can be seen in Figure 3.5. Figure 3.5.a displays the image to be interpolated. The choice we made gives Figure 3.5.b as solution, favoring that the object whose level is 210 goes above the object whose level is 0. But, in that case, the "true" information is lacking and we selected one of the possible reasonable solutions.

3.3J A Variant and Mathematical Results

For the purposes of mathematical analysis and comparison with the implementation in [167], we write the boundary conditions in (3.19) in a relaxed way. In particular, the condition u = U() m B will add the term j^\u - UQ\^ dx in (3.19). To be able to handle noisy data in B and to include the boundary condition 0 ' i^^\dn = ^0 in a variational framework, we add the term / ^ \Du\ - J^^ gou,
Before continuing, let us make precise the functional analytic model for u and 0. We assume that ft is a domain of class C^. We assume that UQ e BV{D \ Q,), and OQ : D\Q. —> 1Z^ is the vector field of directions of the gradient of i^o, i.e., a vector field OQ eL'^iDX 0 , IZ^), such that |l9o| < 1 and

dWOo e LP{B), Oo ' Duo = \Duol

(3.22)

PDE-Based Image and Surface Inpainting

49

where the last identity is understood in the sense of measures in B (therefore, a.e.).
Let us denote by ^p(n, B, OQ) the space of couples {u, 6) where u G BV{Q), <9 is a bounded measurable vector field from ^ to i ? ^ , |(9| < 1, div ((9) G LP{n), e'Du= \Dul U\B e L^{B), O'U^ =goon dQ.
If {u, 0) e Sp{n, J5,6>o) we define

Ep{u,e)

-/

\diY{0)\P{-f-h(3\\/K^u\)dx

Jn

-V a I \Du\ — a I g^u + A / \u — UQ\^ dx

JQ

Jan

JB

(3.23)

where 7, a, A > 0, /^ > 0, p > 1, g > 1.

We propose to interpolate the pair (0, u) in H by solving the minimization problem

Minimize £'p(u,6>), {u, 9) e Spin, B, OQ)

(3.24)

Theorem, Assume that sup^^QQ \9{^)\ < 1- ffp > 1> Q' > 1> 7,0:, A > 0, and (3 >0, then there is a minimum (n, 6) G Sp[Vl^ B, Oo)for the problem (3.24).
The case p = 1 is is particularly interesting, in that case we should consider div ^ to be a Radon measure and we do not know if an existence theorem holds in this case.
The assumption || 5^0! 100 < 1 does not permit the level lines of the topographic map of the image to be tangent to the boundary of the hole Ct. To ensure it, we may slightly change the topographic map by replacing the level lines which are near to the tangent one by a constant gray level, and this gives us more freedom to choose the vector field ^o- On the other hand, the assumption ||po || 00 < 1 permits to prove the convergence (after subsequence extraction) of the minima of the fixnctionals

Minimize / Idiv f

^ ) | {j-^ p\VK ^u\)dx+

+ a / \Du\ -a

gou + X \u- uol'^dx

JQ

JdQ

JB

(3.25)

That is, the minimizers of (3.25) converge (modulo a subsequence) to a minimum of (3.24) as e —> 0+. For that, we proved in [47] the existence of minimizers for both problems and we studied the two operators div (j^^ 1 and div ( > ^^^ ^ J
which appear in (3.23) and (3.25), respectively. Notice that the convergence of minima of (3.25) to minima of (3.24) establishes a connection between the numerical approach of T. Chan and J Shen [167] which is based on the direct minimization of (3.25) and ours. Let us also mention that the authors of [167]

50

Bertalmio, Caselles, Haro & Sapiro

Figure 3.6. Left: Four circles. Right: Reconstructed image.
compared model (3.25) with previous curvature driven diffusion and Total Variation based inpaintings [172, 171]. Their analysis in [172] showed that a curvature term was necessary to have a connectivity principle.
Let us finally mention that a regularity result for the level lines of minimizers of (3.19) or (3.23) has been proved in [47].
3,3.4 Experimental Results
Examples in 2D. In the following experiments we show the results of the joint interpolation of gray level and the vector field of directions using functional (3.19). The experiments have been done with p = \ and/or p = 2. The results are quite similar and, unless explicitly stated, we display the results obtained with p =1.
Figure 3.6 displays an image made of four circles covered by a square (left image) and the result of the interpolation (right image) obtained with p — 2. Figure 3.7.a is a detail of the mouth of Lena with a hole. Figures 3.7.b displays the result of the interpolation using (3.19). Figure 3.7.c shows the result of interpolating the hole of Figure 3.7.a by using a simple algorithm: the value of pixels at distance k from the boundary is the average of its neighboring pixels at distance A; - 1 from the boundary. In Figure 3.7.b we see the effect of continuing the level lines along the mouth, which is not the case in Figure 3.7.C. Figure 3.8.a is an image of a woman with a flower. In Figure 3.8.b we have represented a hole covering the region of the flower. In Figure 3.8.C we display the result of interpolating the hole of Figure 3.8.b using (3.19).
Figure 3.9.a displays an image with text to be removed. Figure 3.9.b displays the corresponding reconstructed result.
Examples in 3D. Let us describe how to use functional (3.19) to inpaint (fill-in) holes (or gaps) on surfaces S, which we assume to be embedded in 71^. To avoid any confusion with our previous use of the word hole, let us use the word gap of the surface. Assume, to fix ideas, that 5 is a smooth compact connected surface, and A^ is a part of iS which is unknown or could not be obtained during scanning. Let us identify S with its known part. Let us choose a bounding box Q in IZ^

PDE-Based Image and Surface Inpainting

51

Figure 3.7. a) Left: Detail of the mouth of Lena, b) Middle: Reconstructed mouth using (3.19). c) Right: Result of interpolating the hole in a) by means of a propagation of neighbouring values.
^^^^^^^^r ^^ll^^^H Figure 3.8. a) Left: woman with flower, b) Middle: woman with a mask on the flower representing the hole, c) Right: Resuh of interpolation using (3.19)

Figure 3.9. Removing the text on an image, a) Left: original image, b) Right: reconstructed image.

52

Bertalmio, Caselles, Haro & Sapiro

strictly containing the gap M and part of <S (see Figs. 3.10.a, 3.10.b). Let dM be the boundary of the gap (a curve or a set of curves in IZ^). Even ifM is unknown, its relative boundary in S is known. Let ^ be a neighborhood of 5 n Q defined by
r ={xeQ: d{x, SnQ) < ad{x, dM)], a > 0.
where d denotes the distance. We assume that ^ \ {SnQ) consists of two connected components, which can be identified as the two sides of the surface S. With this information, we are able to complete an initial surface closing the gap and determining a set A in the interior part of 5 . We take UQ — XA and OQ as the outer unit normal vector field to the known part of 5 in Q [840].
With the purpose of adapting them to our algorithm, the data, originally given as a triangulated surface, were converted to an implicit representation in a regularly spaced 3D grid. The result was visualized again as a triangulated surface. Figures 3.10.a, 3.10.b display some particular holes with a bounding box isolating them (taken from a scanned version of Michelangelo's David [516]). Figures 3.10.C, 3.10.e display the triangulated surface (the data) around the hole. The reconstructed surface is displayed in Figures 3.10.d, 3.10.f These images have been rendered using the AMIRA Visualization and Modeling System [24].
The pioneering work [249] addressed the problem of hole filling via isotropic diffusion of volumetric data (that is, iterative Gaussian convolution of some distance function to the known data). The approach proposed by these authors addresses holes with complicated topology, a task very difficult with mesh representations. Most algorithms on reconstructing surfaces from range data are point-cloud reconstruction based and treat holes as regions with low sampling density, thereby interpolating across them [21,42, 76, 294,404]. Of course, these algorithms do not distinguish between a real hole in the data and one due to the lack of sampling, and equally fill or fail to fill both cases in the same fashion. Other point-cloud methods evolve a surface over time until it approximates the data [186, 888,918], or fit a set of 3D radial basis functions to the data, compute a weighted sum of them and use a level set of this last function as reconstructed surface [270, 150]. Mesh based methods for surface reconstruction [819, 240, 886] can perform hole filling as a post-process or integrate hole filling into surface reconstruction [240].

3.4 Surface Reconstruction: The Laplace and the Absolute Minimizing Lipschitz Extension Interpolation
In [158] we studied and classified the interpolation algorithms which satisfy a reasonable set of axioms in terms of the solution of a partial differential equation. Two particular examples are: the Absolutely Minimizing Lipschitz Extension,

PDE-Based Image and Surface Inpainting

53

Figure 3.10. From top to bottom and left to right: a) David's left hand, b) A detail of its hair, c) A zoomed detail of a) showing the triangulated surface with the hole, d) The reconstruction of the hole in c) displayed as a triangulated surface, e) A zoomed detail of b) showing the triangulated surface with the hole, f) The reconstruction of the hole in e) displayed as a triangulated surface.
denoted as AMLE in the sequel, and the Laplacian interpolation. We study the applicability of both of them to the problem of surface reconstruction.
We use the notation introduced in section 3.3.4. As we said there, we assume that T\{S OQ) consists of two connected components, which can be identified as the two sides of the surface S. By changing the sign of the distance function in one of them, we may define the signed distance function to S OQ which we denote by ds(x). Let us denote Qjr = Q\J^.

54

Bertalmio, Caselles, Haro & Sapiro

The Laplacian interpolation is based on solving the PDE

-Au - 0 in Qjr,

(3.26)

with specified boundary data on dQ:^. Indeed, boundary data is only known in d!F n Q where we should impose that u = dg. Thus, a reasonable assumption

would be to assume that

du —-0

mdQjr\ dT

(3.27)

where u denotes the outer unit normal to dQj: \ dT. Even if this boundary condition is not the most reasonable one to reconstruct the surface «S n Q (which is defined as d\(a > 0]), we have used it in our experiments (see the result).

The AMLE interpolation ([31]) is based on solving the PDE

D^u {Du, Du) = 0 in Qjr.

(3.28)

with boundary data on dQjr (here Du and D'^u denote the gradient and the Hessian matrix of u, respectively, so that in coordinates, D'^u {Du, Du) = J2ij=\. dxidx WIW^"^- ^^^^ equation can be solved with general domains and boundary data, in particular the data can be given in a finite number of surfaces, curves and/or points. Indeed, existence and uniqueness of viscosity solutions of (3.28) were proved in [434] for boundary data (p G C{dQjr). Moreover, as it is proved in [434], the viscosity solution of (3.28) is an absolutely minimizing Lipschitz extension of (/?, i.e., u G M^^'°°(Q:r) H C{Qjr) and satisfies

P^||L-(Q';7^^) < ||^^IU-(Q';7^^)

(3-29)

for all Q' C Qjr and w such that u-w e WQ''^{Q'). Finally, the AMLE is locally Lipschitz continuous in Qjr [434]. Let us mention that the AMLE model was introduced by Aronsson in [31] as the Euler-Lagrange equation of the variational problem (3.29).
As in the case of Laplace equation (3.26), the boundary data is only known in dJ^ n Q where we impose that u = ds (by the results in [445] there exist absolutely minimizing Lipschitz extensions ofds\dj^nQ and satisfy (3.28) but there is no uniqueness result for them). In practice we impose the Neumann boundary condition (3.27) in dQjr \ dJ^. We observe again that even if this boundary condition is not the most reasonable one to reconstruct the surface <S fi Q (which is defined 2isd[u > 0]), we have used it in our experiments (see the result).

3.4.1 Experimental Results
We display the results obtained using the 3D Laplace and AMLE interpolators on some holes of Michelangelo's David [516]. The result are visualized again as a triangulated surface (using the AMIRA Visualization and Modeling System [24]). Figures 3.11.a, 3.1 l.b display the original images with holes. Figures 3.11.C, 3.1 l.d display the result obtained using the Laplace interpolator. Figures

PDE-Based Image and Surface Inpainting

55

Vp^^^m^Bli
^^^^^^m
^^^^1
^^^^^^^^ i^^V'/'lv^^^^^l S g ^ ^ ^ ^ ^ ^ l ^^^t^j^^j^^^^^^H Figure 3.11. From top to bottom and left to right: a) David's left hand with a hole, b) A detail of its hair with a hole, c) and d) The results obtained with Laplace interpolator, e) and f) Results obtained using AMLE interpolator.
3.1 l.e, 3.1 l.f display the result obtained with the AMLE. Observe that the result obtained with AMLE interpolation is less regular.
3.5 Dealing with texture
All the PDE-based approaches to inpainting share the shortcoming that they cannot restore texture. The notion of texture implies a repetitive pattern, a missing portion of which may usually not be restored just by propagating the level lines into the gap in any clever way. On the other hand, there are a number of very good texture synthesis algorithms, which in turn do not give as good results when applied to gaps in 'structured' (as opposed to 'textured') regions. In this section we will comment on two methods to perform inpainting on images with textured and/or structured regions. Both methods use the remarkable algorithm introduced

56

Bertalmio, Caselles, Haro & Sapiro

by Efros and Leung for texture synthesis [297], which gives excellent results for the inpainting problem as well, so we will start by discussing this algorithm.

3.5.1 Texture Synthesis by Non-Parametric Sampling
This algorithm [297] is fully automatic and produces very good texture synthesis results. It is also very well suited to natural images when the regions to be inpainted cover a large variety of textures.
Let the region to be filled be denoted by O. H will be filled, pixel by pixel, proceeding from the border dVt inwards, in an 'onion-peel' fashion. Let p(?', j) be the pixel to fill-in next. We consider a n x n neighborhood of this pixel, call it Nij. This neighborhood will typically contain several empty pixels. With only the filled pixels of N^j, we build the template Tij. Next we compare Tij with all the posible templates Txy, centered at (x, y) and shaped like T^j, that are completely outside n . This comparison is done by computing a distance d(x, y) between both templates, which uses the normalized sum of squared differences (SSD) metric. We keep the set of coordinates (x, y) for which d{x, y) is below a given threshold. From this set, we randomly pick a pixel coordinate (XQ, yo), and copy the image value /(xo,yo) to /(?', j ) . Then, pixel (i, j ) is filled and we procceed to the next empty pixel at the boundary.

3.5,2 Inpainting with Image Decomposition
The basic idea of this algorithm [80] is presented in Figure 3.12, which shows a real result from this approach. The original image (first row, left) is first decomposed into the sum of two images, one capturing the basic image structure and one capturing the texture (and random noise), second row. This follows the work by Vese and Osher reported in [842]. The first image is inpainted following any of the PDE-based approaches described before, while the second one is filled-in with a texture synthesis algorithm, third row. The two reconstructed images are then added back together to obtain the reconstruction of the original data, first row, right. In other words, the general idea is to perform structure inpainting and texture synthesis not on the original image, but on a set of images with very different characteristics that are obtained from decomposing the given data. The decomposition is such that it produces images suited for these two reconstruction algorithms. This approach outperforms both image inpainting and texture synthesis when applied separately. Indeed, a separate reconstruction of missing blocks in wireless JPEG transmission was proposed in [669].
As for the decomposition step, the authors in [842], inspired by [567], propose a model to express any given image / as the sum of two images u and v, where u will be a sketchy or cartoon image of / (with sharp edges) and v will be the the remainder (a term with noise, oscillations, texture.)Expressing then 7(x,y) = u{x, y) + v{x, y) and v(x^2/) = V • {;v\,V2), the authors in [842] propose a minimization problem to find u,v\,V2, whose Euler-Lagrange equations

PDE-Based Image and Surface Inpainting

57

Figure 3.12. Structure and Texture inpainting using image decomposition (see text.)

58

Bertalmio, Caselles, Haro & Sapiro

are
u = / - a . 3 i - 5 , ^ 3 + i - d i v ( ^ ) , (3.30)

M^== \/9\+92
A* ; Jrl . ,

= 2A[—(M-/) +9^51+5^ J ,

^"^

-•

== 22AA[|—^ ( « - / ) + 52^5i+5,V2 .

(3.31) (3.32)

For some theoretical results and the detailed semi-implicit numerical implementation of the above Euler-Lagrange equations, see [842].

5.5.3 Exemplar-based Inpainting
In this work [238], Criminisi et al. propose a variation on [297], where they modify the fill order of the algorithm.
Instead of the 'onion-peel' of [297], patches along the fill front are given a priority value P{i,j), which determines the order in which they are filled. This priority P{i, j) is the product of a confidence term C(i, j) and a data term D{i, j).
The confidence term C(i,j) is an average of the values of C for the neighbors of {i,j); initially, C is 0 for pixels inside Q and 1 for pixels outside. So C gives higher priority to pixels that have more of their neighbors already filled, and to pixels that are closer to dQ.
The data term D{i,j) is proportional to the absolute value of the scalar product of V-^/(i, j), the isophote direction at (?', j ) , and NdQ^{i,j), the normal to the boundary of the fill front. So D gives higher priorities to patches where there is an isophote 'flowing into' the gap.
Finally, ft is filled not one pixel at a time as in [297], but patch by patch, where a patch is the intersection of a n x n window (typically n = 9) with the gap. This speeds up the process considerably.

3.6 Other Approaches
3.6.1 Other PDE-based Models
Other PDE based models have been proposed by Chan and Shen [171, 172, 167]. In [172] the authors proposed an anisotropic diffusion model (called (CCD)) with curvature dependent diffusion coefficient. In [171] they compared several models, namely, TV based inpainting, segmentation-based inpaintings, and the (CCD) model. Finally, in [167], the authors proposed to minimize the Elastica model written as in (3.21) leading to a fourth order PDE gradient descent equation. The connection of this model with model (3.23) has been mentioned in Section 3.3.3. Esedoglu and Shen proposed in [300] an inpainting functional based on Mumford-Sha's functional plus some terms which approximate the Elastica.

PDE-Based Image and Surface Inpainting

59

Inspired by the real Ginzburg-Landau equation which develops homogeneous areas separated by phase transition regions (that are interfaces of minimal area), H. Grossauer and O. Scherzer proposed to use the complex Ginzburg-Landau equation for inpainting [369]. As we did above, we denote by ft the hole to be inpainted and we suppose that the given image UQ : D —> R has been extended in rough way to Ct. Normalizing UQ to take values in [—1,1], the authors defined VQ = y^l - |IAOP, and UQ = (UQ^VQ). Then the authors solve the equation (which corresponds to the gradient descent method applied to the Ginzburg-Landau functional)

^ = Au-^^{l-\u\^)u

inn,

with initial condition tx(0) = UQ and boundary condition

(3.33)

As an interesting feature of (3.33) let us mention that the solution corresponding to the image in Figure 3.5 would be the symmetric one: half gray and half black forming an X in the hole.
Inpainting models based on probability diffusion of orientations are proposed in [844]. Indeed, the authors define the function P{x,0) as the probabiHty that there is a level line passing through x with direction 0 and propose to compute P(x, 0) as the asymptotic state of the PDE
Pt + P(cos 6>, sin 0) • V ^ F = aPee + /^A^P in ft,
where P{x,0){cos ^,sin 9) represents a probabiHty distribution for the tangent direction. This equation also includes an spatial diffusion of the probability P{x,6). Knowing P{x,6), the authors define the orthogonal orientation of the level line through x as the expectation of P{x,0), i.e., as the vector z{x) := /Q ^ ( - sin 0, cos 9)P{x, 6) dO. Then the authors reconstruct the image inside ft using z{x) and the value of the image on dft [844].
A related model has been used in [892, 893] for the completion of illusory contours. The connection between both models is given by the completion of level lines as if they were illusory contours. The model in [892, 893] was inspired by the work of [589] who interpreted the elastica as the mode of the probability distribution underlying the stochastic process given by the differential equations X = (cos ^,sin 0), 0 being a normally distributed random variable with zero mean and given variance.
Let us finally mention that a finite element implementation of the Willmore functional / ^ H^ dS has been used in [202] for surface restoration. As explained in Section 3.3.2, this functional (in a relaxed form) is a term in functional (3.19).
3,6.2 Miscellaneous
Finally, let us briefly mention some other approaches to the inpainting problem.

60

Bertalmio, Caselles, Haro & Sapiro

Jia and Tang [437] perform a texture-based segmentation of the image. Then they find the curves in H that connect texture boundaries arriving at dft: these curves, boundaries between different texture regions, are found with a robust tensor voting algorithm that extrapolates curve shape. Then texture is synthesised inside each region, also with a tensor voting algorithm, where texture at pixel (?', j ) is encoded as a vector of length N = n x n-\-1 whose components are the image intensity values at the n x n neighborhood of (i, j ) .
Levin et al. [515] use global information to guide the inpainting process. They choose features like the norm of the gradient, compute the histogram of these features over the whole image, define a probability taking these histograms into account, and find an integrable gradient field inside ft that maximizes that probability and satisfies the boundary conditions at d^.
Kim and Kim [466] use genetic algorithms to approximate the solution to the problem of minimizing the elastica inside 0 , given the image and curvature values
at^a
Tan et al. [786] perform highlight removal with a proposed variant of inpainting where the region to fill-in ft is not empty but has some useful information, from which the highlights must be substracted.
Patwardhan and Sapiro [634] use wavelets in a Projection Onto Convex Sets (POCS) setting similar to Hirani and Totsuka's [400], but without the need for user-selection of similar neighborhoods. It is an iterative process where in each step the image is wavelet-transformed, its coefficients constrained, then waveletinverse-transformed, the resulting image values also constrained.

3.7 Concluding Remarks
In this chapter we have reviewed the area of image inpainting, which has received a significant amount of attention from the image processing, computer vision, computer graphics, and applied mathematics communities; following the early works of Masnou-Morel [553] and Bertalmio-Sapiro-Caselles-Ballester [79, 46]. We can not forget of course also one of the first works in the area, [605], where the famous Laplacian Pyramid is used to fill-in holes.
Although image inpainting still has many open problems, the main challenges are in the extension of this work to other visual sources, such as video [438, 885] and sensor arrays [905]. Preliminary and very promising results are starting to appear in this subject, and many important advances are expected in forthcoming years.

3.8 Appendix
Let Q be an open subset of R^. By Cg°{Q) (resp. C^{Q\ R^)) we denote the space of functions (resp., vector fields with values in R^) with are C^ and have

PDE-Based Image and Surface Inpainting

61

compact support in Q. By L^(Q), 1 <p< oo, we denote the space of measurable functions / : Q —> R whose p-power is integrable (in the sense of Lebesgue). L^[Q) denotes the space of measurable functions in Q which are essentially bounded. By W^''P{Q), 1 < p < oo, we denote the space of functions u £ LP{Q) such that S/u e L'P{Q). By VKQ'^(Q) we denote the closure ofC^{Q) in W^^'P[Q), Saying that u e W^{Q) is a way of saying that W^'P{Q) mdu^O on the boundary of Q. By C{Q) we denote the space of continuous functions in
QA function u E L^{Q) whose gradient Du in the sense of distributions is a
(vector valued) Radon measure with finite total variation in Q is called a function of bounded variation. The class of such functions will be denoted by BV{Q). The total variation of Du on Q turns out to be

supi / udivzdx : z e C^{Q]R^),snp\z{x)\ < l l ,

(3.34)

(where for a vector v = {v\,..., VN) E R^ we set \v\'^ := Yli^i '^h ^^^ will ^^ denoted by \Du\{Q) or by / g \Du\. The total variation ofu on a Borel set 5 C Q is defined as inf{|Dti|(v4) : A open ,B C AC Q}.
A measurable set E C R^ is said to be of finite perimeter in Q if (3.34) is finite when u is substituted with the characteristic function XE ^ ^ ^ - ^^^ perimeter of £• in Q is defined as P{E,Q) := \DXE\{Q)' We shall use the notation P{E) := P{E, R^). For sets of finite perimeter E one can define the essential boundary d*E, which is countably {N — 1) rectifiable with finite ?{^~^ measure, and compute the outer unit normal iy^{x) at 7{^~^ almost all points x of d*E, where H^~^ is the [N — \) dimensional Hausdorff measure. Moreover, I^^XEI coincides with the restriction ofH^"^ to d*E.
Ifue BV{Q) almost all its level sets [u > X] = {x e Q : u{x) > A} are sets of finite perimeter. Thus at almost all points of almost all level sets of u G BV{Q) we may define a normal vector 0{x) which coincides \Du\'a.Q. with the Radon-Nikodym derivative of the measure Du with respect to \Du\, hence it formally satisfies 9 • Du = \Du\, and also |^| < 1 a.e. (see [19], 3.9). For further information concerning fiinctions of bounded variation we refer to [19, 301, 926].

3.9 Acknowledgments
We thank Marc Levoy and the Stanford Michelangelo Project for data provided for this work. We also thank our collaborators in the work on image inpainting. The first three authors acknowledge partial support by the Departament d'Universitats, Recerca i Societat de la Informacio de la Generalitat de Catalunya and by PNPGC project, reference BFM2003-02125. The first author acknowledges partial support by Programa Ramon y Cajal. The fourth author is partially supported by the Office of Naval Research, the National Science Foundation, the National GeospatialIntelligence Agency, and the McKnight Foundation.

Part II
Boundary Extraction, Segmentation and Grouping

Chapter4
Levelings: Theory and Practice
F. Meyer
Abstract Connected operators enlarge the flat zones of an image and never create a contour where no contour was present. This definition is too vague to be useful in practice, except for binary images. For grey-tone images a more precise characterization has to be given in order to be operational. This leads to the introduction offloodings,razings,flatteningsand levelings. Extending the notion of a flat zone and of a contour leads to extended connected operators. The chapter concludes by showing the versatility and power of these operators in practice.
4.1 Introduction
Filtering is ubiquitous in image processing before compression or segmentation, for suppressing noise or simplifying images. An ideal filter should suppress noise and unwanted details without degrading in any other respect the image. For instance it should not blur or displace the contours if one wishes to segment the filtered image. It should not create spurious structures such as minima or maxima if the aim is to describe the topography of a relief or to construct its watershed line. Each element in the filtered image should be traceable in the initial image.
It seems difficult to design a filter complying with all these constraints. Linear filters produce a blurring of the image. The problem is to find a good trade-off between smoothing and localization of the contours: a large smoothing simplifies the detection but creates poorly localized contours whereas a reduced smoothing does not suppress enough noise. Non linear smoothing techniques [642] avoid smoothing across object boundaries. However, depending on a number of parameters, they are difficult to tune. Alternate sequential filters based on openings and closings also displace the contours [724].
Connected operators do not suffer from this drawback, they enlarge the existing flat zones and produce new ones [726]. They are specially designed for simplifying images without blurring or displacing contours. The simplest ones

66

Meyer

suppress particles or holes in binary images [725]. Clipping peaks and filling valleys until a plateau of a given size is produced constitutes the area openings and closings introduced by Luc Vincent [845]. Particle reconstruction allows to suppress all connected particles not containing a marker. Applied on each threshold of a grey tone image, one obtains reconstruction openings and closings. [367, 846]. They are both members of a larger family, operating symmetrically on peaks and valleys, which comprises flattenings and razings [564],[555]. Their scale space properties and PDE formulation are studied in [566].
The present paper gives an insight in the nature and construction of these operators and illustrates their use. As we are concerned with practical applications we will restrict ourselves to a digital framework. Let T be some complete totally ordered lattice, and let V,S be arbitrary sets in the discrete space. We call O the smallest element and O the largest element of T. Fun(X>,T) represents the image defined on the support V with value in T . The value of function / at pixel p will be written fp. A presentation of levelings and flattenings in the continuous space may be found in [555], [565].

4.2 Binary connected operators
The functions f,g,h met in this section are binary and are the indicator functions of binary sets, being equal to 1 in the particles and to 0 in the holes. A binary connected operator suppresses particles and/or fills holes:
Definition 1. A connected operator transforms an image f into an image g in such a way that thefollowing relation is verifiedfor allpairs of neighboring pixels : V (p, q) neighbors: fp = fq=^gp = g^ or equivalently gp^g^^ fp^ fq (1).
The relation (1) expresses that any contour between the pixels p and q in the destination image g corresponds to a contour in the initial image / at the same place. There is however no coupHng between the directions of the transitions: between p and q, the function g may for instance be increasing and / decreasing. Relation (1) may be rewritten as gp > gq => fp > fq or fp < /^(Ibis). As an example, the complementation of a binary image is a connected operator. This shows that a connected operator may turn a regional minimum into a maximum and vice-versa. If a function g and a function / verify relation (1) for all pairs of pixels, we say that by definition gisa. planing of / .
Planings may be specialized in 3 ways :
• A planing verifying g > f only suppresses holes and is called flooding. It is characterized by g > f and V (p, q) neighbors: gp > g^ =^ fp = gp[= 1) (2)
• Planings which only suppress particles are called razings and verify g < f. They are characterized by: ^^ < / and V (p, q) neighbors: gp > gq =^ /,=ff<,(=0)(3)

Levelings: Theory and Practice

67

dyyu

Figure 4.1. g^ < gp =-> gp = fp
• Monotone planings are called levelings. They may suppress both particles and holes but if a hole and a particle are adjacent, the hole cannot become a particle and simultaneously the particle a hole. Levelings introduce a coupling between the directions of the transitions: between p and q : 9v>9q^ fp> fq (4).
When applied to each threshold of a grey-tone function, these binary operators generate interesting grey-tone operators.

4.3 Flat grey-tone connected operators

4.3.1 Level by level construction

The definitions of planings and monotone planings given in the preceding section

still make sense if g and h are grey-tone functions. Relations (2) and (3) fully

specify floodings and razings for grey-tone functions. Relation (2) has an obvious

physical meaning. Fig.4.1 A and Fig.4.1B represent respectively a possible and an

impossible flooding p of a relief / : if for two comparable pixels a lake verifies

9q < 9v> then the highest pixel is necessarily at ground level {g^ = /p), otherwise

the lake presents an unconstrained wall of water as in fig.4.1B.

On the contrary the relations (1) and (4) indicate that to any contour of g

corresponds a contour of / at the same location, but do not establish a relation

between the values of the functions themselves. However, applying the corre-

sponding binary operators on each threshold of a grey-tone function produces a

well constrained operator: a function gisdi flattening (resp. leveling) of a function

/ if and only if for each t, X^ (g) is a planing (resp. monotone planing) of X* (/)

(where X^ (/) = {x \ f{x) < t}). We derive the following criteria:

- An image p is a flattening of the image / iffV (p, q) neighbors:

[ fp>9p and gq > fq 1

9p> 9q=^ \

or

(5)

[ fq>9p and 9q > fp \

* An image ^^ is a leveling of the image / iff V (p, q) neighbors:

9p> 9q^ fp> 9p and gq > fq (6).

Basically relation (5) means that any transition in the destination image g is

bracketed by a larger variation in the source image. If furthermore the direction of

68

Meyer

the transitions is always the same as in relation (6),flatteningsbecome levelings. Flattenings arefloodingsif they verify g> f and razings ifg<f.

4.3.2 A morphological characterization
Interesting characterizations may be derived from the relations (6) and (7). As an example consider the implication [g-p > gq => gq > fq] which is part of relation (6). Recalling that the logical meaning of [A ^ B] is [notA or B] it may interpreted as [gp < gq or gq > fq] 4^ [gq > fq A gp]. As p may be any element of the neighborhood Nq of the central point g, we obtain gq > fq A V g^ equivalent
xeNg

^o gq > fq A i gq\/ \J gx ] = fq A Sgq, where S represents the elementary

\ xeN^ J

morphological dilation with aflatstructuring element containing the central point

and all its neighbors. Taking into account the complete relation (6) yields the

following criterion for levelings: f ASg < g < f y eg.

Since g < Sg and eg < g, the preceding criterion is equivalent with

{fASg)\/eg<g<{fy

eg) A Sg. But (/ A Sg) W eg = {f y eg) A Sg, giving

another criterion for leveHngs: g = {f A Sg) ^ eg = {f V eg) A Sg, known as the

morphological centre [724] between Sg and eg.

The criterion characterizingflattenings,floodingsand razings may be estab-

lished in a similar way:

* A function ^^ is a flattening of / if and only if : f A S {f A g) < g <

fye{fyg)(9)

* A function g is SLfloodingof / if and only if: g — f W eg

* A function ^f is a razing of / if and only if: g = f A Sg

In the next stage of generalization, the operators no longer commute with

anamorphosis, as it is the case for operators constructed threshold by threshold.

4.4 Extended connected operators

Replacing {S,e) by a more general adjunction (a,/?), where P is an arbitrary erosion verifying P < Id and a > Id its adjunct dilation, we get a generalized leveling g = (f y Pg) Aag = {f A ag) V Pg. For which type offlatzones is it a connected operator ?
We have the equivalence g = {f y Pg) A ag <^ f A ag < g < f V pg. A pixel p verifying gp < (/ V pg)^^ also verifies the following equivalent

expressions: ^gp < {pg)^ or gp < / p j <^ |^p > {Pg)^^ =^ gp < fpj (10)

The relation gp > {Pg)p means that eroding the function g with the erosion p

decreases the value of g at pixel p, indicating that p has a lower neighbor for

the function g. In order to find this neighbor, we have to introduce the pulse

>./ f tifx=^h 1 1 ,/ / \ f tifx = h 1 ^

fonctions Tk= [oifx^hj

^"'^ ^^ ^^^ = | fi if ^ ^ /. / ' ^^""^ """

Levelings: Theory and Practice

69

age g of Fun(2),T) can be written g ^ \l T?"=- A i?" and [pg)^ =

( A \9s.

p

A /^ fix'' ) . The minimal value in this expression is xev

attai\nxeedv at a pixel x = q. This pixel q is the lower "neighbor" of p we are look-

ing for, and we write gq ^ gp ^ gp > Pqp(gq), where Pqp{gq) = [(3 (1?")]^

is an erosion. Since gp < ft, the relation gp > Pqp{gq) also indicates that

Pqpigq) < ^- When this is the case, we consider that p and q are a/?—neighbors

for the adjunction (a, P). pqp has an adjunct dilation ap^q (gp) = [a {'\p')] , ver-

ifying : gp > Pq^p (gq) <^ ap^q (gp) > gq. Finally relation (10) may be rewritten

for any a/^—neighbors p and q'. gq U. gp ^ gp < fp-

The inequality f A ag < g may be treated in the same manner and putting

everything together, we obtain the characterization of levelings: ^ is a leveling of

/ if \/{p,q) a/3-neighbors gq [Z gp => fp > gp and gq > fq, quite similar to

relation (6).

As a summary we have found a general mechanism for defining transitions

between pixels for a given function, based on an adjunction {a,P). Definitions

and characterizations of extended flattenings, fioodings, razings and levelings are

obtained by simply replacing {6, s) by (a, /?) and the relation < by the relation c

in all relations and definitions of the previous sections.

Negating the relation C yields the relation Zl: for (p, q) a/?-neighbors, gq 3 9p

if only if ^p < Pq^p {gq) <^ ap^q {gp) < gq. When the relations {fy ^ f^} and

{fx 3 fy} are simultaneously true, we obtain a symmetrical relation written fx o

fy, expressing that there is a smooth transition between fy and fx or that fx and fy

are at the same a/^-level: {fx - fy} <=> {O < ax,y {fx) < fy < Px,y{fx) < ^}

<^ {O < ay^x {fy) <fx< PyAfy) < ^}We are now able to define smooth zones based on arcwise connectivity.

Definition 2. We say that two values fx and fy are smoothly linked and we write fx txi fy if there exists a series of pixels [XQ = x, xi,X2, ...x'n = y} such that
JXi ^ JXi + l-

Definition 3. A set X is a smooth zone of an image f if and only if fx ix fyfor any two pixels x and y in X.

The relation txi is an equivalence relation. The associated equivalence classes are the maximal smooth zones. It is easy to verify that the smooth zones of / form a connection of V [725]. For the pair of elementary dilation and erosion {6, e), one obtains ordinary flat zones.

Definition 4. A set X is uniformly smooth if fx o fyfor any couple {x,y) of ap-neighbors in X.

For the slope dilation 6i {g) = g y {6g - I), X = 3. 2. is a smooth zone since there exists a path with a slope smaller or equal to 1 between any couple of

70

Meyer

pixels. However, there exists within X a. sharp transition between values 1 and 4,

hence X is not a uniformly smooth zone.

Levelings enlarge smooth zones: g^ IZ gp => fq n fp is equivalent with

fq^fp=^gq^

gp from which we derive fq>^fp ^ gq ^ gp] this last relation

shows that any smooth (resp. uniformly smooth) zone for / is also a smooth zone

(resp. uniformly smooth) for g. Levelings are indeed connected operators [700].

Levelings create smooth zones: Any zone where {g > / } (resp. {g < / } ) is

uniformly smooth.

Regional minima

If (a, p) are flat operators, then the leveling based on (a, (3) does not create re-

gional minima or maxima. More precisely if ^f is a leveling of/, and X a regional

minimum of g, then there exists a set Z C X, which is a regional minimum for

/ . However, this is not true if (a, /3) are not flat operators.

4.4.1 Construction offloodings, razings, flattenings and levelings

We call Inter [g, f) the class of functions h e T ^ , verifying g A f < h < gy f. We say that g is farther away from / than h, or that g is bigger than h in the order f and we write g >/ h if and only ifh G Inter {g, / ) [555].

Proposition 1, >f is an order relation on T^. For a, / C T^, Inter (a, / ) is a

complete lattice for the order f. The function a is then the highest element. For

anyfamily hi o/Inter (a, / ) ;

Nfhi

yhi on {a < / } Ahi on {a > / }

;\/fhi

Ahi on {a < / } Vhi on {a > / }

Considering a pair of functions / and h we will now study the family of floodings, razings and levelings of/ within Inter (/, h).

4.4.1.1 Construction of floodings, razings, flattenings and levelings
Each flooding o f / verifies g > f. For this reason the order relations > / and > are identical. If {gi) is a family of floodings of / , then \J gi also is a flooding of / . The family of floodings of / belonging to Inter (/, h) is not empty and its maximal element is written F l ( / , h). It is obtained by finite iteration until stability of /in = / V 0hn-i, with ho = f y h. We recognize the usual reconstruction closing if/? = £[846].
Similarly the largest razing of/ for the order relation > / in Inter (/, h), which is also the smallest razing for the order relation > is equal to / \ / i n , where hn = f A a / i n - i , with ho = f Ah ]WQ write Rz(/, h). It is obtained by finite iteration until hn-\-i = hn.
The supremum for Vy of a family of flattenings belonging to Inter (/, h) is still a flattening. The largest flattening of Inter (/, h) is also the supremum between the largest flooding and the largest razing within Inter (/, h): H(/, h) = Fl(/,/i)V;Rz(/,/i).

Levelings: Theory and Practice

71

Figure 4.2. Levelings with increasing slopes of the same reference and marker functions.
The supremum V/ of two levelings is not necessarily a leveling but a flattening. However if we replace h by k = ah A f Ph, then all flattenings in Inter (/, A;) are levelings. Hence we will define the leveling of / constrained by h and write A(/, h) as the largest flattening contained in Inter (/, k): A(/, h) = S ( / , k) = Fl(/,A:)V;Rz(/,A;).
Fast algorithms, based for instance on hierarchical queues [563] exist for reconstruction closings and openings, producing respectively floodings and razings. Since flattenings and levelings rely on floodings and razings, their construction is fast also.
4.5 Levelings for image simplification
Floodings Fl(/,/i), razings Rz(/,/i), flattenings S ( / , / i ) and levelings A(/,/i) are all functions of two arguments and depend on these two arguments. Their

72

Meyer

Figure 4.3. Non connected structuring element
flat zones are larger than the flat zones of / , their contours correspond to contours of / ; at the same time they are as close to h as possible in the lattice Inter (/, h). Furthermore, for each choice of an adjunction (a, p) a new operator can be constructed, to which is associated a particular type of contours and flat
4.5.1 Varying {a, P)
We will first explore the effect of various couples {a,P) on the same reference and marker images. Starting with the ordinary flat dilation S (maximum value in a neighborhood of size 1), we define the slope dilation Sx = IdV {S — A), where Id is the identity) . The adjunct slope erosion is defined by £x = Id A (e + A). Two neighboring pixels p and q are at level if |/p - /q| < A. Fig.4.2 presents a picture by Seurat which is extremely grainy. The marker function is an alternate sequential filter of size 4, giving a very crude approximation of the image. We compare the results of 3 levelings ; the first being flat, the next being obtained for slopes 1 and 2. Increasing the slope produces much larger flat zones and a much smoother image. Nevertheless the contours remain sharp.

Figure 4.4. Left: / =original image. The marker image h is completely black with a white dot on the left hand of the girl. Center: leveling associated to the dilation 5'^'^ and erosion £~~; Right : leveling associated to the dilation S and erosion e ; without jumps, the reconstruction is much less complete (see for instance the books)
In our second example we compare two levelings based respectively on a non connected and a connected structuring element. The first leveling is associated to the dilation J"*"*" and its adjunct erosion e and is based on a non connected structuring element consisting of a hexagon and two pixels at a distance of 4 pixels apart on each side (see fig. 4.3). The central part cares for the normal connectivity reconstructions whereas the couple of added pixels permits jumps from one zone

