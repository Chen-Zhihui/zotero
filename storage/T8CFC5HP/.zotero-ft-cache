
Cornell University
Cornell University Library
We gratefully acknowledge support from
the Simons Foundation
and member institutions
arXiv.org > cs > arXiv:1805.09298
( Help | Advanced search )
Full-text links:
Download:

    PDF
    Other formats

( license )
Current browse context:
cs.LG
< prev  |  next >
new  | recent  | 1805
Change to browse by:
cs
cs.CV
stat
stat.ML
References & Citations

    NASA ADS

DBLP - CS Bibliography
listing | bibtex
Weiyang Liu
Rongmei Lin
Zhen Liu
Lixin Liu
Zhiding Yu
...
Bookmark
( what is this? )
CiteULike logo BibSonomy logo Mendeley logo del.icio.us logo Digg logo Reddit logo ScienceWISE logo
Computer Science > Machine Learning
Title: Learning towards Minimum Hyperspherical Energy
Authors: Weiyang Liu , Rongmei Lin , Zhen Liu , Lixin Liu , Zhiding Yu , Bo Dai , Le Song
(Submitted on 23 May 2018 ( v1 ), last revised 16 Jun 2018 (this version, v4))

    Abstract: Neural networks are a powerful class of nonlinear functions that can be trained end-to-end on various applications. While the over-parametrization nature in many neural networks renders the ability to fit complex functions and the strong representation power to handle challenging tasks, it also leads to highly correlated neurons that can hurt the generalization ability and incur unnecessary computation cost. As a result, how to regularize the network to avoid undesired representation redundancy becomes an important issue. To this end, we draw inspiration from a well-known problem in physics -- Thomson problem, where one seeks to find a state that distributes N electrons on a unit sphere as even as possible with minimum potential energy. In light of this intuition, we reduce the redundancy regularization problem to generic energy minimization, and propose a minimum hyperspherical energy (MHE) objective as generic regularization for neural networks. We also propose a few novel variants of MHE, and provide some insights from a theoretical point of view. Finally, we apply networks with MHE regularization to several challenging tasks. Extensive experiments demonstrate the effectiveness of our method, by showing the superior performance with MHE regularization. 

Comments: 	Technical Report v4
Subjects: 	Machine Learning (cs.LG) ; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)
Cite as: 	arXiv:1805.09298 [cs.LG]
  	(or arXiv:1805.09298v4 [cs.LG] for this version)
Submission history
From: Weiyang Liu [ view email ]
[v1] Wed, 23 May 2018 17:34:47 GMT (8356kb,D)
[v2] Tue, 5 Jun 2018 21:50:09 GMT (8356kb,D)
[v3] Wed, 13 Jun 2018 22:44:57 GMT (8356kb,D)
[v4] Sat, 16 Jun 2018 07:47:21 GMT (8365kb,D)
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

Link back to: arXiv , form interface , contact .
Twitter
